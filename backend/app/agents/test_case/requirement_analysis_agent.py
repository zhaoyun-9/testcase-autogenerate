"""
éœ€æ±‚è§£ææ™ºèƒ½ä½“
ä¸“é—¨è´Ÿè´£å¯¹å…¶ä»–æ™ºèƒ½ä½“ä¼ å…¥çš„è½¯ä»¶éœ€æ±‚æ–‡æ¡£å†…å®¹è¿›è¡Œä¼ä¸šçº§ä¸“ä¸šçš„éœ€æ±‚è§£æ
åŸºäºAutoGen Coreæ¶æ„å®ç°ï¼Œå‚è€ƒdocument_parser_agent.pyçš„ä¼˜ç§€è®¾è®¡æ¨¡å¼
"""
import uuid
import json
import asyncio
from typing import Dict, List, Any, Optional
from datetime import datetime

from autogen_agentchat.base import TaskResult
from autogen_agentchat.messages import ModelClientStreamingChunkEvent
from autogen_core import message_handler, type_subscription, MessageContext, TopicId
from loguru import logger
from pydantic import BaseModel, Field

from app.core.agents.base import BaseAgent
from app.core.types import TopicTypes, AgentTypes, AGENT_NAMES
from app.core.messages.test_case import (
    RequirementAnalysisRequest, RequirementAnalysisResponse,
    TestPointExtractionRequest, TestCaseData
)
from app.core.enums import TestType, TestLevel, Priority, InputSource
from app.agents.database.requirement_saver_agent import RequirementSaveRequest


class RequirementAnalysisResult(BaseModel):
    """éœ€æ±‚è§£æç»“æœ"""
    analysis_type: str = Field(..., description="è§£æç±»å‹")
    document_title: str = Field(..., description="æ–‡æ¡£æ ‡é¢˜")
    executive_summary: str = Field(..., description="æ‰§è¡Œæ‘˜è¦")
    functional_requirements: List[Dict[str, Any]] = Field(default_factory=list, description="åŠŸèƒ½éœ€æ±‚")
    non_functional_requirements: List[Dict[str, Any]] = Field(default_factory=list, description="éåŠŸèƒ½éœ€æ±‚")
    business_processes: List[Dict[str, Any]] = Field(default_factory=list, description="ä¸šåŠ¡æµç¨‹")
    user_stories: List[Dict[str, Any]] = Field(default_factory=list, description="ç”¨æˆ·æ•…äº‹")
    acceptance_criteria: List[Dict[str, Any]] = Field(default_factory=list, description="éªŒæ”¶æ ‡å‡†")
    stakeholders: List[Dict[str, Any]] = Field(default_factory=list, description="åˆ©ç›Šç›¸å…³è€…")
    constraints: List[Dict[str, Any]] = Field(default_factory=list, description="çº¦æŸæ¡ä»¶")
    assumptions: List[Dict[str, Any]] = Field(default_factory=list, description="å‡è®¾æ¡ä»¶")
    dependencies: List[Dict[str, Any]] = Field(default_factory=list, description="ä¾èµ–å…³ç³»")
    risks: List[Dict[str, Any]] = Field(default_factory=list, description="é£é™©è¯†åˆ«")
    success_metrics: List[Dict[str, Any]] = Field(default_factory=list, description="æˆåŠŸæŒ‡æ ‡")
    confidence_score: float = Field(0.0, description="è§£æç½®ä¿¡åº¦")


@type_subscription(topic_type=TopicTypes.REQUIREMENT_ANALYZER.value)
class RequirementAnalysisAgent(BaseAgent):
    """éœ€æ±‚è§£ææ™ºèƒ½ä½“ï¼Œä¸“é—¨è´Ÿè´£ä¼ä¸šçº§ä¸“ä¸šçš„éœ€æ±‚è§£æ"""

    def __init__(self, model_client_instance=None, **kwargs):
        """åˆå§‹åŒ–éœ€æ±‚è§£ææ™ºèƒ½ä½“"""
        super().__init__(
            agent_id=AgentTypes.REQUIREMENT_ANALYZER.value,
            agent_name=AGENT_NAMES.get(AgentTypes.REQUIREMENT_ANALYZER.value, "éœ€æ±‚è§£ææ™ºèƒ½ä½“"),
            model_client_instance=model_client_instance,
            **kwargs
        )
        
        # éœ€æ±‚è§£æé…ç½®
        self.analysis_config = {
            'enable_functional_analysis': True,
            'enable_non_functional_analysis': True,
            'enable_business_process_analysis': True,
            'enable_stakeholder_analysis': True,
            'enable_risk_analysis': True,
            'enable_dependency_analysis': True,
            'confidence_threshold': 0.7,
            'max_requirements_per_category': 50
        }
        
        logger.info(f"éœ€æ±‚è§£ææ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ: {self.agent_name}")

    @message_handler
    async def handle_requirement_analysis_request(
        self,
        message: RequirementAnalysisRequest,
        ctx: MessageContext
    ) -> None:
        """å¤„ç†éœ€æ±‚è§£æè¯·æ±‚"""
        start_time = datetime.now()

        try:
            logger.info(f"å¼€å§‹å¤„ç†éœ€æ±‚è§£æè¯·æ±‚: {message.session_id}")

            # å‘é€å¼€å§‹å¤„ç†æ¶ˆæ¯
            await self.send_response(
                f"ğŸ” å¼€å§‹ä¼ä¸šçº§éœ€æ±‚è§£æ: {message.source_type}",
                region="process"
            )

            # å‘é€éœ€æ±‚ä¿¡æ¯
            content_length = len(message.requirement_content)
            await self.send_response(
                f"ğŸ“„ éœ€æ±‚ä¿¡æ¯: å†…å®¹é•¿åº¦ {content_length} å­—ç¬¦, æ¥æº: {message.source_type}",
                region="info"
            )

            # æ‰§è¡Œéœ€æ±‚è§£æ
            await self.send_response("ğŸ”„ ç¬¬1æ­¥: å¼€å§‹æ·±åº¦éœ€æ±‚è§£æ...", region="progress")
            analysis_result = await self._analyze_requirement_content(message)

            # å‘é€è§£æç»“æœç»Ÿè®¡
            await self.send_response(
                f"ğŸ“Š è§£æç»“æœ: åŠŸèƒ½éœ€æ±‚ {len(analysis_result.functional_requirements)} ä¸ª, "
                f"éåŠŸèƒ½éœ€æ±‚ {len(analysis_result.non_functional_requirements)} ä¸ª, "
                f"ä¸šåŠ¡æµç¨‹ {len(analysis_result.business_processes)} ä¸ª",
                region="info",
                result={
                    "functional_requirements_count": len(analysis_result.functional_requirements),
                    "non_functional_requirements_count": len(analysis_result.non_functional_requirements),
                    "business_processes_count": len(analysis_result.business_processes),
                    "stakeholders_count": len(analysis_result.stakeholders),
                    "confidence_score": analysis_result.confidence_score
                }
            )

            # ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å»ºè®®
            await self.send_response("ğŸ”„ ç¬¬2æ­¥: åŸºäºéœ€æ±‚è§£æç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å»ºè®®...", region="progress")
            test_cases = await self._generate_test_cases_from_analysis(
                analysis_result, message
            )

            # å‘é€æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆç»“æœ
            await self.send_response(
                f"âœ… æˆåŠŸç”Ÿæˆ {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹å»ºè®®",
                region="success",
                result={"test_cases_count": len(test_cases)}
            )

            # ä¿å­˜éœ€æ±‚åˆ°æ•°æ®åº“
            if analysis_result.functional_requirements or analysis_result.non_functional_requirements:
                await self.send_response("ğŸ”„ ç¬¬3æ­¥: ä¿å­˜è§£æçš„éœ€æ±‚åˆ°æ•°æ®åº“...", region="progress")
                await self._save_analyzed_requirements_to_database(analysis_result, message)

            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = (datetime.now() - start_time).total_seconds()

            # æ„å»ºå“åº”
            response = RequirementAnalysisResponse(
                session_id=message.session_id,
                analysis_id=str(uuid.uuid4()),
                requirement_content=message.requirement_content,
                analysis_result=analysis_result.model_dump(),
                requirements=analysis_result.functional_requirements + analysis_result.non_functional_requirements,
                business_processes=analysis_result.business_processes,
                stakeholders=analysis_result.stakeholders,
                constraints=analysis_result.constraints,
                dependencies=analysis_result.dependencies,
                processing_time=processing_time,
                created_at=datetime.now().isoformat()
            )

            # å‘é€å®Œæˆæ¶ˆæ¯
            await self.send_response(
                f"âœ… éœ€æ±‚è§£æå®Œæˆ! å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’",
                is_final=False,
                region="success",
                result={
                    "processing_time": processing_time,
                    "total_requirements": len(response.requirements),
                    "total_business_processes": len(response.business_processes),
                    "total_stakeholders": len(response.stakeholders),
                    "confidence_score": analysis_result.confidence_score
                }
            )

            # å‘é€åˆ°æµ‹è¯•ç‚¹æå–æ™ºèƒ½ä½“
            await self.send_response("ğŸ”„ è½¬å‘åˆ°æµ‹è¯•ç‚¹æå–æ™ºèƒ½ä½“è¿›è¡Œä¸“ä¸šæµ‹è¯•ç‚¹æå–...", region="info")
            await self._send_to_test_point_extractor(response)

        except Exception as e:
            processing_time = (datetime.now() - start_time).total_seconds()
            logger.error(f"éœ€æ±‚è§£æå¤±è´¥: {str(e)}")
            await self.send_response(
                f"âŒ éœ€æ±‚è§£æå¤±è´¥: {str(e)} (å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’)",
                is_final=True,
                region="error",
                result={"processing_time": processing_time, "error": str(e)}
            )

    async def _analyze_requirement_content(
        self, 
        message: RequirementAnalysisRequest
    ) -> RequirementAnalysisResult:
        """åˆ†æéœ€æ±‚å†…å®¹"""
        try:
            # åˆ›å»ºAIåˆ†ææ™ºèƒ½ä½“
            agent = self._create_requirement_analysis_agent()
            
            # æ„å»ºåˆ†ææç¤º
            analysis_prompt = self._build_requirement_analysis_prompt(message)
            
            # æ‰§è¡ŒAIåˆ†æ
            analysis_result = await self._run_ai_analysis(agent, analysis_prompt)
            
            # è§£æAIå“åº”
            return self._parse_ai_analysis_result(analysis_result, message)
            
        except Exception as e:
            logger.error(f"AIéœ€æ±‚åˆ†æå¤±è´¥: {str(e)}")
            # è¿”å›åŸºç¡€è§£æç»“æœ
            return RequirementAnalysisResult(
                analysis_type="basic",
                document_title="éœ€æ±‚æ–‡æ¡£",
                executive_summary="è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥è¾“å…¥å†…å®¹",
                functional_requirements=[],
                non_functional_requirements=[],
                business_processes=[],
                user_stories=[],
                acceptance_criteria=[],
                stakeholders=[],
                constraints=[],
                assumptions=[],
                dependencies=[],
                risks=[],
                success_metrics=[],
                confidence_score=0.3
            )

    def _create_requirement_analysis_agent(self):
        """åˆ›å»ºéœ€æ±‚åˆ†ææ™ºèƒ½ä½“"""
        from app.agents.factory import agent_factory

        return agent_factory.create_assistant_agent(
            name="requirement_analyzer",
            system_message=self._build_requirement_analysis_system_prompt(),
            model_client_type="deepseek"
        )

    def _build_requirement_analysis_system_prompt(self) -> str:
        """æ„å»ºéœ€æ±‚åˆ†æç³»ç»Ÿæç¤º"""
        return """
ä½ æ˜¯èµ„æ·±çš„ä¼ä¸šçº§éœ€æ±‚åˆ†æä¸“å®¶ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„è½¯ä»¶éœ€æ±‚å·¥ç¨‹ç»éªŒï¼Œæ“…é•¿ä»å¤æ‚çš„éœ€æ±‚æ–‡æ¡£ä¸­æå–å’Œåˆ†æå„ç±»éœ€æ±‚ä¿¡æ¯ã€‚

ä½ çš„ä¸“ä¸šèƒ½åŠ›åŒ…æ‹¬ï¼š
1. æ·±åº¦ç†è§£ä¸šåŠ¡éœ€æ±‚å’ŒæŠ€æœ¯éœ€æ±‚
2. è¯†åˆ«åŠŸèƒ½éœ€æ±‚å’ŒéåŠŸèƒ½éœ€æ±‚
3. åˆ†æä¸šåŠ¡æµç¨‹å’Œç”¨æˆ·æ•…äº‹
4. è¯†åˆ«åˆ©ç›Šç›¸å…³è€…å’Œçº¦æŸæ¡ä»¶
5. è¯„ä¼°éœ€æ±‚ä¾èµ–å…³ç³»å’Œé£é™©
6. åˆ¶å®šéªŒæ”¶æ ‡å‡†å’ŒæˆåŠŸæŒ‡æ ‡

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ä¼ä¸šçº§éœ€æ±‚åˆ†æç»“æœï¼š
{
    "analysis_type": "enterprise",
    "document_title": "æ–‡æ¡£æ ‡é¢˜",
    "executive_summary": "æ‰§è¡Œæ‘˜è¦ï¼Œæ¦‚è¿°ä¸»è¦éœ€æ±‚å’Œç›®æ ‡",
    "functional_requirements": [
        {
            "id": "FR-001",
            "title": "åŠŸèƒ½éœ€æ±‚æ ‡é¢˜",
            "description": "è¯¦ç»†æè¿°",
            "priority": "high/medium/low",
            "complexity": "high/medium/low",
            "category": "æ ¸å¿ƒåŠŸèƒ½/è¾…åŠ©åŠŸèƒ½/ç®¡ç†åŠŸèƒ½",
            "acceptance_criteria": ["éªŒæ”¶æ ‡å‡†1", "éªŒæ”¶æ ‡å‡†2"],
            "business_value": "ä¸šåŠ¡ä»·å€¼æè¿°"
        }
    ],
    "non_functional_requirements": [
        {
            "id": "NFR-001",
            "title": "éåŠŸèƒ½éœ€æ±‚æ ‡é¢˜",
            "description": "è¯¦ç»†æè¿°",
            "type": "performance/security/usability/reliability/scalability",
            "priority": "high/medium/low",
            "measurable_criteria": "å¯é‡åŒ–æ ‡å‡†",
            "testing_approach": "æµ‹è¯•æ–¹æ³•"
        }
    ],
    "business_processes": [
        {
            "id": "BP-001",
            "name": "ä¸šåŠ¡æµç¨‹åç§°",
            "description": "æµç¨‹æè¿°",
            "steps": ["æ­¥éª¤1", "æ­¥éª¤2", "æ­¥éª¤3"],
            "actors": ["å‚ä¸è€…1", "å‚ä¸è€…2"],
            "inputs": ["è¾“å…¥1", "è¾“å…¥2"],
            "outputs": ["è¾“å‡º1", "è¾“å‡º2"],
            "business_rules": ["ä¸šåŠ¡è§„åˆ™1", "ä¸šåŠ¡è§„åˆ™2"]
        }
    ],
    "user_stories": [
        {
            "id": "US-001",
            "title": "ç”¨æˆ·æ•…äº‹æ ‡é¢˜",
            "as_a": "ä½œä¸ºæŸç§ç”¨æˆ·",
            "i_want": "æˆ‘å¸Œæœ›",
            "so_that": "ä»¥ä¾¿äº",
            "acceptance_criteria": ["éªŒæ”¶æ ‡å‡†1", "éªŒæ”¶æ ‡å‡†2"],
            "priority": "high/medium/low",
            "story_points": ä¼°ç®—ç‚¹æ•°
        }
    ],
    "stakeholders": [
        {
            "name": "åˆ©ç›Šç›¸å…³è€…åç§°",
            "role": "è§’è‰²",
            "responsibilities": ["èŒè´£1", "èŒè´£2"],
            "influence": "high/medium/low",
            "interest": "high/medium/low"
        }
    ],
    "constraints": [
        {
            "type": "technical/business/legal/time/budget",
            "description": "çº¦æŸæè¿°",
            "impact": "å½±å“ç¨‹åº¦",
            "mitigation": "ç¼“è§£æªæ–½"
        }
    ],
    "dependencies": [
        {
            "type": "internal/external/technical/business",
            "description": "ä¾èµ–æè¿°",
            "impact": "å½±å“ç¨‹åº¦",
            "risk_level": "high/medium/low"
        }
    ],
    "risks": [
        {
            "description": "é£é™©æè¿°",
            "probability": "high/medium/low",
            "impact": "high/medium/low",
            "mitigation": "ç¼“è§£ç­–ç•¥"
        }
    ],
    "success_metrics": [
        {
            "metric": "æˆåŠŸæŒ‡æ ‡åç§°",
            "description": "æŒ‡æ ‡æè¿°",
            "target": "ç›®æ ‡å€¼",
            "measurement_method": "æµ‹é‡æ–¹æ³•"
        }
    ],
    "confidence_score": 0.95
}

æ³¨æ„ï¼š
- æ·±å…¥åˆ†æéœ€æ±‚å†…å®¹ï¼Œå‡†ç¡®è¯†åˆ«å„ç±»éœ€æ±‚ä¿¡æ¯
- ä¼˜å…ˆè¯†åˆ«æ ¸å¿ƒä¸šåŠ¡éœ€æ±‚å’Œå…³é”®åŠŸèƒ½ç‚¹
- ä¸ºæ¯ä¸ªéœ€æ±‚åˆ†é…åˆé€‚çš„ä¼˜å…ˆçº§å’Œå¤æ‚åº¦
- ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œå»æ‰ ```json å’Œ ```
- åˆ†æè¦å…¨é¢ã€ä¸“ä¸šã€ç»“æ„åŒ–
"""

    def _build_requirement_analysis_prompt(
        self,
        message: RequirementAnalysisRequest
    ) -> str:
        """æ„å»ºéœ€æ±‚åˆ†ææç¤º"""
        return f"""
è¯·å¯¹ä»¥ä¸‹è½¯ä»¶éœ€æ±‚å†…å®¹è¿›è¡Œä¼ä¸šçº§ä¸“ä¸šåˆ†æï¼š

æ¥æºç±»å‹: {message.source_type}
é¡¹ç›®ID: {message.project_id or "default-project-001"}
åˆ†æé…ç½®: {json.dumps(message.analysis_config or {}, ensure_ascii=False, indent=2)}

éœ€æ±‚å†…å®¹ï¼š
{message.requirement_content[:15000]}  # é™åˆ¶å†…å®¹é•¿åº¦é¿å…tokenè¶…é™

è¯·æ ¹æ®éœ€æ±‚å†…å®¹ï¼Œè¿›è¡Œå…¨é¢çš„ä¼ä¸šçº§éœ€æ±‚åˆ†æï¼ŒåŒ…æ‹¬ï¼š
1. åŠŸèƒ½éœ€æ±‚è¯†åˆ«å’Œåˆ†ç±»
2. éåŠŸèƒ½éœ€æ±‚æå–å’Œé‡åŒ–
3. ä¸šåŠ¡æµç¨‹æ¢³ç†å’Œå»ºæ¨¡
4. ç”¨æˆ·æ•…äº‹ç¼–å†™å’Œä¼˜å…ˆçº§æ’åº
5. åˆ©ç›Šç›¸å…³è€…è¯†åˆ«å’Œåˆ†æ
6. çº¦æŸæ¡ä»¶å’Œä¾èµ–å…³ç³»åˆ†æ
7. é£é™©è¯†åˆ«å’Œç¼“è§£ç­–ç•¥
8. æˆåŠŸæŒ‡æ ‡å®šä¹‰å’Œæµ‹é‡æ–¹æ³•

è¯·ç¡®ä¿åˆ†æç»“æœä¸“ä¸šã€å…¨é¢ã€å¯æ“ä½œã€‚
"""

    async def _run_ai_analysis(self, agent, prompt: str) -> str:
        """æ‰§è¡ŒAIåˆ†æ"""
        try:
            stream = agent.run_stream(task=prompt)
            async for event in stream:  # type: ignore
                # æµå¼æ¶ˆæ¯ï¼Œåªæ˜¯ä¸ºäº†åœ¨å‰ç«¯ç•Œé¢æµå¼æ˜¾ç¤º
                if isinstance(event, ModelClientStreamingChunkEvent):
                    # ä¸´æ—¶æ³¨é‡Šï¼Œä¸åœ¨å‰ç«¯æ˜¾ç¤ºæµå¼å†…å®¹
                    # await self.send_response(content=event.content, source=self.id.key)
                    continue

                # æœ€ç»ˆçš„å®Œæ•´ç»“æœ
                if isinstance(event, TaskResult):
                    messages = event.messages
                    # ä»æœ€åä¸€æ¡æ¶ˆæ¯ä¸­è·å–å®Œæ•´å†…å®¹
                    if messages and hasattr(messages[-1], 'content'):
                        return messages[-1].content

            # å¦‚æœæ²¡æœ‰è·å–åˆ°ç»“æœï¼Œè¿”å›é»˜è®¤å€¼
            return """
                {
                    "analysis_type": "enterprise",
                    "document_title": "éœ€æ±‚åˆ†ææ–‡æ¡£",
                    "executive_summary": "éœ€æ±‚åˆ†æå®Œæˆ",
                    "functional_requirements": [],
                    "non_functional_requirements": [],
                    "business_processes": [],
                    "user_stories": [],
                    "acceptance_criteria": [],
                    "stakeholders": [],
                    "constraints": [],
                    "assumptions": [],
                    "dependencies": [],
                    "risks": [],
                    "success_metrics": [],
                    "confidence_score": 0.8
                }
                """
        except Exception as e:
            logger.error(f"AIåˆ†ææ‰§è¡Œå¤±è´¥: {str(e)}")
            # è¿”å›é»˜è®¤ç»“æœè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
            return """
{
    "analysis_type": "enterprise",
    "document_title": "è§£æå¤±è´¥",
    "executive_summary": "éœ€æ±‚åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥è¾“å…¥å†…å®¹",
    "functional_requirements": [],
    "non_functional_requirements": [],
    "business_processes": [],
    "user_stories": [],
    "acceptance_criteria": [],
    "stakeholders": [],
    "constraints": [],
    "assumptions": [],
    "dependencies": [],
    "risks": [],
    "success_metrics": [],
    "confidence_score": 0.5
}
"""

    def _parse_ai_analysis_result(
        self,
        ai_result: str,
        message: RequirementAnalysisRequest
    ) -> RequirementAnalysisResult:
        """è§£æAIåˆ†æç»“æœ"""
        try:
            # å°è¯•è§£æJSON
            result_data = json.loads(ai_result.replace("```json", "").replace("```", ""))

            return RequirementAnalysisResult(
                analysis_type=result_data.get("analysis_type", "enterprise"),
                document_title=result_data.get("document_title", "éœ€æ±‚åˆ†ææ–‡æ¡£"),
                executive_summary=result_data.get("executive_summary", ""),
                functional_requirements=result_data.get("functional_requirements", []),
                non_functional_requirements=result_data.get("non_functional_requirements", []),
                business_processes=result_data.get("business_processes", []),
                user_stories=result_data.get("user_stories", []),
                acceptance_criteria=result_data.get("acceptance_criteria", []),
                stakeholders=result_data.get("stakeholders", []),
                constraints=result_data.get("constraints", []),
                assumptions=result_data.get("assumptions", []),
                dependencies=result_data.get("dependencies", []),
                risks=result_data.get("risks", []),
                success_metrics=result_data.get("success_metrics", []),
                confidence_score=result_data.get("confidence_score", 0.5)
            )

        except json.JSONDecodeError:
            logger.warning("AIè¿”å›ç»“æœä¸æ˜¯æœ‰æ•ˆJSONï¼Œä½¿ç”¨é»˜è®¤è§£æ")
            return RequirementAnalysisResult(
                analysis_type="basic",
                document_title="è§£æå¤±è´¥",
                executive_summary="éœ€æ±‚åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥è¾“å…¥å†…å®¹",
                functional_requirements=[],
                non_functional_requirements=[],
                business_processes=[],
                user_stories=[],
                acceptance_criteria=[],
                stakeholders=[],
                constraints=[],
                assumptions=[],
                dependencies=[],
                risks=[],
                success_metrics=[],
                confidence_score=0.3
            )

    async def _generate_test_cases_from_analysis(
        self,
        analysis_result: RequirementAnalysisResult,
        message: RequirementAnalysisRequest
    ) -> List[TestCaseData]:
        """ä»éœ€æ±‚åˆ†æç»“æœç”Ÿæˆæµ‹è¯•ç”¨ä¾‹"""
        test_cases = []

        try:
            # åŸºäºåŠŸèƒ½éœ€æ±‚ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
            for req in analysis_result.functional_requirements:
                test_case = TestCaseData(
                    title=f"æµ‹è¯•åŠŸèƒ½éœ€æ±‚: {req.get('title', 'æœªå‘½ååŠŸèƒ½éœ€æ±‚')}",
                    description=req.get("description", ""),
                    test_type=TestType.FUNCTIONAL,
                    test_level=TestLevel.SYSTEM,
                    priority=self._map_priority(req.get("priority", "medium")),
                    input_source=InputSource.MANUAL,
                    source_metadata={
                        "requirement_id": req.get("id"),
                        "requirement_type": "functional",
                        "business_value": req.get("business_value"),
                        "complexity": req.get("complexity")
                    },
                    ai_confidence=analysis_result.confidence_score
                )
                test_cases.append(test_case)

            # åŸºäºéåŠŸèƒ½éœ€æ±‚ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
            for req in analysis_result.non_functional_requirements:
                test_type = self._map_non_functional_test_type(req.get("type", "performance"))
                test_case = TestCaseData(
                    title=f"æµ‹è¯•éåŠŸèƒ½éœ€æ±‚: {req.get('title', 'æœªå‘½åéåŠŸèƒ½éœ€æ±‚')}",
                    description=req.get("description", ""),
                    test_type=test_type,
                    test_level=TestLevel.SYSTEM,
                    priority=self._map_priority(req.get("priority", "medium")),
                    input_source=InputSource.MANUAL,
                    source_metadata={
                        "requirement_id": req.get("id"),
                        "requirement_type": "non_functional",
                        "nfr_type": req.get("type"),
                        "measurable_criteria": req.get("measurable_criteria"),
                        "testing_approach": req.get("testing_approach")
                    },
                    ai_confidence=analysis_result.confidence_score
                )
                test_cases.append(test_case)

            # åŸºäºä¸šåŠ¡æµç¨‹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
            for process in analysis_result.business_processes:
                test_case = TestCaseData(
                    title=f"æµ‹è¯•ä¸šåŠ¡æµç¨‹: {process.get('name', 'æœªå‘½åä¸šåŠ¡æµç¨‹')}",
                    description=f"éªŒè¯ä¸šåŠ¡æµç¨‹: {process.get('description', '')}",
                    test_type=TestType.FUNCTIONAL,
                    test_level=TestLevel.INTEGRATION,
                    priority=Priority.P1,  # ä¸šåŠ¡æµç¨‹é€šå¸¸æ˜¯é«˜ä¼˜å…ˆçº§
                    input_source=InputSource.MANUAL,
                    source_metadata={
                        "process_id": process.get("id"),
                        "process_steps": process.get("steps", []),
                        "process_actors": process.get("actors", []),
                        "business_rules": process.get("business_rules", [])
                    },
                    ai_confidence=analysis_result.confidence_score
                )
                test_cases.append(test_case)

            # åŸºäºç”¨æˆ·æ•…äº‹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
            for story in analysis_result.user_stories:
                test_case = TestCaseData(
                    title=f"æµ‹è¯•ç”¨æˆ·æ•…äº‹: {story.get('title', 'æœªå‘½åç”¨æˆ·æ•…äº‹')}",
                    description=f"ä½œä¸º{story.get('as_a', 'ç”¨æˆ·')}ï¼Œæˆ‘å¸Œæœ›{story.get('i_want', '')}ï¼Œä»¥ä¾¿äº{story.get('so_that', '')}",
                    test_type=TestType.FUNCTIONAL,
                    test_level=TestLevel.ACCEPTANCE,
                    priority=self._map_priority(story.get("priority", "medium")),
                    input_source=InputSource.MANUAL,
                    source_metadata={
                        "story_id": story.get("id"),
                        "story_points": story.get("story_points"),
                        "acceptance_criteria": story.get("acceptance_criteria", [])
                    },
                    ai_confidence=analysis_result.confidence_score
                )
                test_cases.append(test_case)

            logger.info(f"ä»éœ€æ±‚åˆ†æç”Ÿæˆäº† {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
            return test_cases

        except Exception as e:
            logger.error(f"ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å¤±è´¥: {str(e)}")
            return []

    def _map_non_functional_test_type(self, nfr_type: str) -> TestType:
        """æ˜ å°„éåŠŸèƒ½éœ€æ±‚ç±»å‹åˆ°æµ‹è¯•ç±»å‹"""
        mapping = {
            "performance": TestType.PERFORMANCE,
            "security": TestType.SECURITY,
            "usability": TestType.USABILITY,
            "reliability": TestType.FUNCTIONAL,
            "scalability": TestType.PERFORMANCE,
            "compatibility": TestType.COMPATIBILITY,
            "maintainability": TestType.FUNCTIONAL
        }
        return mapping.get(nfr_type.lower(), TestType.FUNCTIONAL)

    def _map_priority(self, priority_str: str) -> Priority:
        """æ˜ å°„ä¼˜å…ˆçº§"""
        mapping = {
            "high": Priority.P1,
            "medium": Priority.P2,
            "low": Priority.P3,
            "critical": Priority.P0,
            "P0": Priority.P0,
            "P1": Priority.P1,
            "P2": Priority.P2,
            "P3": Priority.P3,
            "P4": Priority.P4
        }
        return mapping.get(priority_str, Priority.P2)

    async def _send_to_test_point_extractor(
        self,
        response: RequirementAnalysisResponse
    ):
        """å‘é€åˆ°æµ‹è¯•ç‚¹æå–æ™ºèƒ½ä½“"""
        try:
            extraction_request = TestPointExtractionRequest(
                session_id=response.session_id,
                requirement_analysis_result=response.analysis_result,
                extraction_config={
                    "enable_functional_extraction": True,
                    "enable_non_functional_extraction": True,
                    "enable_integration_extraction": True,
                    "enable_boundary_extraction": True,
                    "enable_exception_extraction": True,
                    "enable_security_extraction": True,
                    "enable_performance_extraction": True,
                    "enable_risk_based_extraction": True,
                    "confidence_threshold": 0.75
                },
                test_strategy="comprehensive",
                project_id="default-project-001"  # å¯ä»¥ä»åŸå§‹è¯·æ±‚ä¸­è·å–
            )

            await self.publish_message(
                extraction_request,
                topic_id=TopicId(type=TopicTypes.TEST_POINT_EXTRACTOR.value, source=self.id.key)
            )

            logger.info(f"å·²å‘é€åˆ°æµ‹è¯•ç‚¹æå–æ™ºèƒ½ä½“: {response.session_id}")

        except Exception as e:
            logger.error(f"å‘é€åˆ°æµ‹è¯•ç‚¹æå–æ™ºèƒ½ä½“å¤±è´¥: {str(e)}")



    async def _save_analyzed_requirements_to_database(
        self,
        analysis_result: RequirementAnalysisResult,
        message: RequirementAnalysisRequest
    ) -> None:
        """ä¿å­˜åˆ†æçš„éœ€æ±‚åˆ°æ•°æ®åº“"""
        try:
            # åˆå¹¶åŠŸèƒ½éœ€æ±‚å’ŒéåŠŸèƒ½éœ€æ±‚
            all_requirements = []

            # æ·»åŠ åŠŸèƒ½éœ€æ±‚
            for req in analysis_result.functional_requirements:
                req_data = {
                    "id": req.get("id", f"FR-{uuid.uuid4().hex[:8].upper()}"),
                    "title": req.get("title", "æœªå‘½ååŠŸèƒ½éœ€æ±‚"),
                    "description": req.get("description", ""),
                    "type": "functional",
                    "priority": req.get("priority", "medium"),
                    "category": req.get("category", "æ ¸å¿ƒåŠŸèƒ½"),
                    "complexity": req.get("complexity", "medium"),
                    "business_value": req.get("business_value", ""),
                    "acceptance_criteria": req.get("acceptance_criteria", []),
                    "confidence": analysis_result.confidence_score
                }
                all_requirements.append(req_data)

            # æ·»åŠ éåŠŸèƒ½éœ€æ±‚
            for req in analysis_result.non_functional_requirements:
                req_data = {
                    "id": req.get("id", f"NFR-{uuid.uuid4().hex[:8].upper()}"),
                    "title": req.get("title", "æœªå‘½åéåŠŸèƒ½éœ€æ±‚"),
                    "description": req.get("description", ""),
                    "type": "non_functional",
                    "priority": req.get("priority", "medium"),
                    "nfr_type": req.get("type", "performance"),
                    "measurable_criteria": req.get("measurable_criteria", ""),
                    "testing_approach": req.get("testing_approach", ""),
                    "confidence": analysis_result.confidence_score
                }
                all_requirements.append(req_data)

            await self.send_response(
                f"ğŸ’¾ å¼€å§‹ä¿å­˜ {len(all_requirements)} ä¸ªåˆ†æçš„éœ€æ±‚åˆ°æ•°æ®åº“...",
                region="process"
            )

            # æ„å»ºéœ€æ±‚ä¿å­˜è¯·æ±‚
            requirement_save_request = RequirementSaveRequest(
                session_id=message.session_id,
                document_id=str(uuid.uuid4()),
                file_name="éœ€æ±‚åˆ†æç»“æœ",
                file_path="requirement_analysis",
                requirements=all_requirements,
                project_id=message.project_id,
                ai_model_info={
                    "model": "deepseek-chat",
                    "generation_time": datetime.now().isoformat(),
                    "agent_version": "1.0",
                    "agent_type": "requirement_analyzer",
                    "session_id": message.session_id,
                    "confidence_score": analysis_result.confidence_score,
                    "analysis_type": analysis_result.analysis_type
                }
            )

            # å‘é€åˆ°éœ€æ±‚å­˜å‚¨æ™ºèƒ½ä½“
            await self.publish_message(
                requirement_save_request,
                topic_id=TopicId(type=TopicTypes.REQUIREMENT_SAVER.value, source=self.id.key)
            )

            logger.info(f"å·²å‘é€éœ€æ±‚ä¿å­˜è¯·æ±‚åˆ°éœ€æ±‚å­˜å‚¨æ™ºèƒ½ä½“: {message.session_id}")

        except Exception as e:
            logger.error(f"ä¿å­˜åˆ†æçš„éœ€æ±‚åˆ°æ•°æ®åº“å¤±è´¥: {str(e)}")
            await self.send_response(
                f"âš ï¸ éœ€æ±‚ä¿å­˜å¤±è´¥: {str(e)}",
                region="warning"
            )
