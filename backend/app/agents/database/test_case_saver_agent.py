"""
æµ‹è¯•ç”¨ä¾‹æ•°æ®åº“ä¿å­˜æ™ºèƒ½ä½“ - ä¼˜åŒ–ç‰ˆæœ¬
ä¸“é—¨è´Ÿè´£å°†æµ‹è¯•ç”¨ä¾‹æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“
éµå¾ªå•ä¸€èŒè´£åŸåˆ™ï¼Œä¸“æ³¨äºæ•°æ®æŒä¹…åŒ–æ“ä½œ
"""
import uuid
import json
from typing import Dict, List, Any, Optional
from datetime import datetime

from autogen_core import message_handler, type_subscription, MessageContext, TopicId
from loguru import logger
from pydantic import BaseModel, Field

from app.core.agents.base import BaseAgent
from app.core.types import TopicTypes, AgentTypes, AGENT_NAMES
from app.core.messages.test_case import TestCaseData
from app.database.connection import db_manager
from app.database.repositories.test_case_repository import TestCaseRepository
from app.database.repositories.requirement_repository import RequirementRepository, TestCaseRequirementRepository
from app.database.models.test_case import (
    TestCaseCreateRequest, TestCaseResponse
)
from app.database.models.requirement import (
    TestCaseRequirementCreateRequest
)
from app.core.enums import (
    TestType, TestLevel, Priority, InputSource
)


class TestCaseSaveRequest(BaseModel):
    """æµ‹è¯•ç”¨ä¾‹ä¿å­˜è¯·æ±‚"""
    session_id: str = Field(..., description="ä¼šè¯ID")
    test_cases: List[TestCaseData] = Field(..., description="æµ‹è¯•ç”¨ä¾‹æ•°æ®åˆ—è¡¨")
    project_id: Optional[str] = Field(None, description="é¡¹ç›®ID")
    created_by: Optional[str] = Field(None, description="åˆ›å»ºäººID")
    source_metadata: Optional[Dict[str, Any]] = Field(None, description="æºæ•°æ®å…ƒä¿¡æ¯")
    requirement_mappings: Optional[Dict[str, List[str]]] = Field(None, description="æµ‹è¯•ç”¨ä¾‹ä¸éœ€æ±‚çš„æ˜ å°„å…³ç³»")


class TestCaseSaveResponse(BaseModel):
    """æµ‹è¯•ç”¨ä¾‹ä¿å­˜å“åº”"""
    session_id: str = Field(..., description="ä¼šè¯ID")
    success: bool = Field(..., description="æ˜¯å¦æˆåŠŸ")
    saved_count: int = Field(0, description="ä¿å­˜æˆåŠŸçš„æ•°é‡")
    failed_count: int = Field(0, description="ä¿å­˜å¤±è´¥çš„æ•°é‡")
    saved_test_cases: List[Dict[str, Any]] = Field(default_factory=list, description="ä¿å­˜æˆåŠŸçš„æµ‹è¯•ç”¨ä¾‹")
    errors: List[str] = Field(default_factory=list, description="é”™è¯¯ä¿¡æ¯")
    processing_time: float = Field(0.0, description="å¤„ç†æ—¶é—´")


@type_subscription(topic_type=TopicTypes.TEST_CASE_SAVER.value)
class TestCaseSaverAgent(BaseAgent):
    """
    æµ‹è¯•ç”¨ä¾‹æ•°æ®åº“ä¿å­˜æ™ºèƒ½ä½“ - ä¼˜åŒ–ç‰ˆæœ¬

    èŒè´£ï¼š
    1. æ¥æ”¶æµ‹è¯•ç”¨ä¾‹ä¿å­˜è¯·æ±‚
    2. æ•°æ®éªŒè¯å’Œè½¬æ¢
    3. æ‰¹é‡ä¿å­˜æ“ä½œ
    4. äº‹åŠ¡ç®¡ç†å’Œé”™è¯¯å¤„ç†
    5. ä¿å­˜ç»“æœåé¦ˆ

    è®¾è®¡åŸåˆ™ï¼š
    - å•ä¸€èŒè´£ï¼šä¸“æ³¨äºæ•°æ®æŒä¹…åŒ–
    - äº‹åŠ¡å®‰å…¨ï¼šç¡®ä¿æ•°æ®ä¸€è‡´æ€§
    - æ‰¹é‡å¤„ç†ï¼šæ”¯æŒé«˜æ•ˆçš„æ‰¹é‡æ“ä½œ
    - é”™è¯¯æ¢å¤ï¼šå®Œå–„çš„é”™è¯¯å¤„ç†å’Œå›æ»šæœºåˆ¶
    """

    def __init__(self, **kwargs):
        """åˆå§‹åŒ–æµ‹è¯•ç”¨ä¾‹ä¿å­˜æ™ºèƒ½ä½“"""
        super().__init__(
            agent_id=AgentTypes.TEST_CASE_SAVER.value,
            agent_name=AGENT_NAMES.get(AgentTypes.TEST_CASE_SAVER.value, "æµ‹è¯•ç”¨ä¾‹ä¿å­˜æ™ºèƒ½ä½“"),
            **kwargs
        )

        # åˆå§‹åŒ–ä»“å‚¨
        self.test_case_repository = TestCaseRepository()
        self.requirement_repository = RequirementRepository()
        self.test_case_requirement_repository = TestCaseRequirementRepository()

        # åˆå§‹åŒ–æ€§èƒ½æŒ‡æ ‡
        self.save_metrics = {
            "total_requests": 0,
            "successful_saves": 0,
            "failed_saves": 0,
            "total_test_cases_saved": 0,
            "average_processing_time": 0.0,
            "batch_sizes": []
        }

        # ä¿å­˜é…ç½®
        self.save_config = {
            "batch_size": 50,   # æ‰¹é‡ä¿å­˜å¤§å°
            "commit_interval": 10,  # æ¯å¤„ç†å¤šå°‘ä¸ªæµ‹è¯•ç”¨ä¾‹æäº¤ä¸€æ¬¡
            "max_retries": 3,   # æœ€å¤§é‡è¯•æ¬¡æ•°
            "retry_delay": 1.0, # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
            "enable_transaction": True,  # å¯ç”¨äº‹åŠ¡
            "enable_parallel_processing": False,  # å¯ç”¨å¹¶è¡Œå¤„ç†
            "max_concurrent_saves": 5,  # æœ€å¤§å¹¶å‘ä¿å­˜æ•°
            "enable_batch_validation": True,  # å¯ç”¨æ‰¹é‡éªŒè¯
            "rollback_on_error": True  # é”™è¯¯æ—¶å›æ»š
        }

        logger.info(f"æµ‹è¯•ç”¨ä¾‹ä¿å­˜æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ: {self.agent_name}")

    @message_handler
    async def handle_test_case_save_request(
        self,
        message: TestCaseSaveRequest,
        ctx: MessageContext
    ) -> TestCaseSaveResponse:
        """
        å¤„ç†æµ‹è¯•ç”¨ä¾‹ä¿å­˜è¯·æ±‚ - ä¼˜åŒ–ç‰ˆæœ¬

        æµç¨‹ï¼š
        1. æ•°æ®éªŒè¯
        2. æ‰¹é‡ä¿å­˜å¤„ç†
        3. äº‹åŠ¡ç®¡ç†
        4. é”™è¯¯å¤„ç†å’Œé‡è¯•
        5. ç»“æœåé¦ˆ
        """
        start_time = datetime.now()
        self.save_metrics["total_requests"] += 1

        try:
            logger.info(f"å¼€å§‹å¤„ç†æµ‹è¯•ç”¨ä¾‹ä¿å­˜è¯·æ±‚: {message.session_id}")

            await self.send_response(
                f"ğŸ’¾ å¼€å§‹ä¿å­˜ {len(message.test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹åˆ°æ•°æ®åº“...",
                region="process"
            )

            # æ•°æ®éªŒè¯
            if not await self._validate_save_request(message):
                return await self._handle_validation_error(message, start_time)

            # æ‰¹é‡ä¿å­˜å¤„ç†
            save_result = await self._save_test_cases_with_retry(message)

            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = (datetime.now() - start_time).total_seconds()
            save_result.processing_time = processing_time

            # æ›´æ–°æŒ‡æ ‡
            if save_result.success:
                self.save_metrics["successful_saves"] += 1
                self.save_metrics["total_test_cases_saved"] += save_result.saved_count
            else:
                self.save_metrics["failed_saves"] += 1

            self.save_metrics["batch_sizes"].append(len(message.test_cases))
            self._update_average_processing_time(start_time)

            # å‘é€å“åº”
            await self._send_save_response(save_result)

            # å‘å¸ƒä¿å­˜ç»“æœåˆ°æµå¼è¾“å‡º
            await self.publish_message(
                save_result,
                topic_id=TopicId(type=TopicTypes.STREAM_OUTPUT.value, source=self.id.key)
            )

            return save_result

        except Exception as e:
            return await self._handle_save_error(message, e, start_time)

    async def _validate_save_request(self, message: TestCaseSaveRequest) -> bool:
        """éªŒè¯ä¿å­˜è¯·æ±‚"""
        if not message.test_cases:
            logger.warning(f"ä¿å­˜è¯·æ±‚ä¸­æ²¡æœ‰æµ‹è¯•ç”¨ä¾‹æ•°æ®: {message.session_id}")
            return False

        if len(message.test_cases) > 1000:  # é™åˆ¶æ‰¹é‡å¤§å°
            logger.warning(f"æ‰¹é‡ä¿å­˜æ•°é‡è¿‡å¤§: {len(message.test_cases)}")
            return False

        return True

    async def _handle_validation_error(
        self,
        message: TestCaseSaveRequest,
        start_time: datetime
    ) -> TestCaseSaveResponse:
        """å¤„ç†éªŒè¯é”™è¯¯"""
        error_response = TestCaseSaveResponse(
            session_id=message.session_id,
            success=False,
            saved_count=0,
            failed_count=len(message.test_cases),
            errors=["æ•°æ®éªŒè¯å¤±è´¥"],
            processing_time=(datetime.now() - start_time).total_seconds()
        )

        await self.send_response(
            "âŒ æ•°æ®éªŒè¯å¤±è´¥ï¼Œæ— æ³•ä¿å­˜æµ‹è¯•ç”¨ä¾‹",
            is_final=True
        )

        return error_response

    async def _save_test_cases_with_retry(
        self,
        message: TestCaseSaveRequest
    ) -> TestCaseSaveResponse:
        """å¸¦é‡è¯•çš„ä¿å­˜æµ‹è¯•ç”¨ä¾‹"""
        last_error = None

        for attempt in range(self.save_config["max_retries"]):
            try:
                if attempt > 0:
                    await self.send_response(f"ğŸ”„ ç¬¬ {attempt + 1} æ¬¡é‡è¯•ä¿å­˜...")
                    import asyncio
                    await asyncio.sleep(self.save_config["retry_delay"])

                return await self._save_test_cases_to_database(message)

            except Exception as e:
                last_error = e
                logger.warning(f"ä¿å­˜å°è¯• {attempt + 1} å¤±è´¥: {str(e)}")

        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        return TestCaseSaveResponse(
            session_id=message.session_id,
            success=False,
            saved_count=0,
            failed_count=len(message.test_cases),
            errors=[f"é‡è¯• {self.save_config['max_retries']} æ¬¡åä»ç„¶å¤±è´¥: {str(last_error)}"]
        )

    async def _send_save_response(self, save_result: TestCaseSaveResponse):
        """å‘é€ä¿å­˜å“åº”"""
        if save_result.success:
            await self.send_response(
                f"âœ… æµ‹è¯•ç”¨ä¾‹ä¿å­˜å®Œæˆï¼ŒæˆåŠŸä¿å­˜ {save_result.saved_count} ä¸ªç”¨ä¾‹",
                is_final=True,
                result=save_result.model_dump()
            )
        else:
            await self.send_response(
                f"âŒ æµ‹è¯•ç”¨ä¾‹ä¿å­˜å¤±è´¥ï¼ŒæˆåŠŸ {save_result.saved_count} ä¸ªï¼Œå¤±è´¥ {save_result.failed_count} ä¸ª",
                is_final=True,
                result=save_result.model_dump()
            )

    async def _handle_save_error(
        self,
        message: TestCaseSaveRequest,
        error: Exception,
        start_time: datetime
    ) -> TestCaseSaveResponse:
        """å¤„ç†ä¿å­˜é”™è¯¯"""
        logger.error(f"æµ‹è¯•ç”¨ä¾‹ä¿å­˜å¤±è´¥: {str(error)}")
        self.save_metrics["failed_saves"] += 1

        error_response = TestCaseSaveResponse(
            session_id=message.session_id,
            success=False,
            saved_count=0,
            failed_count=len(message.test_cases),
            errors=[str(error)],
            processing_time=(datetime.now() - start_time).total_seconds()
        )

        await self.send_response(
            f"âŒ æµ‹è¯•ç”¨ä¾‹ä¿å­˜å¼‚å¸¸: {str(error)}",
            is_final=True,
        )

        await self.publish_message(
            error_response,
            topic_id=TopicId(type=TopicTypes.STREAM_OUTPUT.value, source=self.id.key)
        )

        return error_response

    async def _save_test_cases_to_database(self, message: TestCaseSaveRequest) -> TestCaseSaveResponse:
        """ä¿å­˜æµ‹è¯•ç”¨ä¾‹åˆ°æ•°æ®åº“ - ä¼˜åŒ–ç‰ˆæœ¬"""
        response = TestCaseSaveResponse(
            session_id=message.session_id,
            success=False
        )

        try:
            # æ‰¹é‡éªŒè¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.save_config["enable_batch_validation"]:
                await self.send_response("ğŸ” æ­£åœ¨è¿›è¡Œæ‰¹é‡æ•°æ®éªŒè¯...")
                validation_results = await self._batch_validate_test_cases(message.test_cases)
                valid_test_cases = [tc for tc, valid in zip(message.test_cases, validation_results) if valid["is_valid"]]
                invalid_count = len(message.test_cases) - len(valid_test_cases)

                if invalid_count > 0:
                    await self.send_response(f"âš ï¸ å‘ç° {invalid_count} ä¸ªæ— æ•ˆæµ‹è¯•ç”¨ä¾‹ï¼Œå°†è·³è¿‡ä¿å­˜")
            else:
                valid_test_cases = message.test_cases

            # åˆ†æ‰¹å¤„ç†
            batch_size = self.save_config["batch_size"]
            total_batches = (len(valid_test_cases) + batch_size - 1) // batch_size

            all_saved_test_cases = []
            all_errors = []

            for batch_index in range(total_batches):
                start_idx = batch_index * batch_size
                end_idx = min(start_idx + batch_size, len(valid_test_cases))
                batch_test_cases = valid_test_cases[start_idx:end_idx]

                await self.send_response(f"ğŸ“¦ æ­£åœ¨å¤„ç†ç¬¬ {batch_index + 1}/{total_batches} æ‰¹æ•°æ® ({len(batch_test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹)...")

                # å¤„ç†å½“å‰æ‰¹æ¬¡
                batch_result = await self._save_test_case_batch(
                    batch_test_cases, message, start_idx
                )

                all_saved_test_cases.extend(batch_result["saved_test_cases"])
                all_errors.extend(batch_result["errors"])

                # æ‰¹æ¬¡é—´çŸ­æš‚ä¼‘æ¯ï¼Œé¿å…æ•°æ®åº“å‹åŠ›è¿‡å¤§
                if batch_index < total_batches - 1:
                    import asyncio
                    await asyncio.sleep(0.1)

            # æ„å»ºæœ€ç»ˆå“åº”
            response.success = len(all_saved_test_cases) > 0
            response.saved_count = len(all_saved_test_cases)
            response.failed_count = len(all_errors)
            response.saved_test_cases = all_saved_test_cases
            response.errors = all_errors

            logger.info(f"æ‰¹é‡ä¿å­˜å®Œæˆ: æˆåŠŸ {response.saved_count} ä¸ªï¼Œå¤±è´¥ {response.failed_count} ä¸ª")

        except Exception as e:
            logger.error(f"æ‰¹é‡ä¿å­˜æµ‹è¯•ç”¨ä¾‹å¼‚å¸¸: {str(e)}")
            response.success = False
            response.failed_count = len(message.test_cases)
            response.errors = [str(e)]

        return response

    async def _batch_validate_test_cases(self, test_cases: List[TestCaseData]) -> List[Dict[str, Any]]:
        """æ‰¹é‡éªŒè¯æµ‹è¯•ç”¨ä¾‹"""
        validation_results = []

        for test_case_data in test_cases:
            validation_result = await self.validate_test_case_data(test_case_data)
            validation_results.append(validation_result)

        return validation_results

    async def _save_test_case_batch(
        self,
        batch_test_cases: List[TestCaseData],
        message: TestCaseSaveRequest,
        start_index: int
    ) -> Dict[str, Any]:
        """ä¿å­˜ä¸€æ‰¹æµ‹è¯•ç”¨ä¾‹"""
        saved_test_cases = []
        errors = []

        try:
            async with db_manager.get_session() as session:
                for i, test_case_data in enumerate(batch_test_cases):
                    global_index = start_index + i + 1

                    try:
                        # æ•°æ®éªŒè¯ï¼ˆå¦‚æœæœªè¿›è¡Œæ‰¹é‡éªŒè¯ï¼‰
                        if not self.save_config["enable_batch_validation"]:
                            validation_result = await self.validate_test_case_data(test_case_data)
                            if not validation_result["is_valid"]:
                                error_msg = f"ç¬¬ {global_index} ä¸ªæµ‹è¯•ç”¨ä¾‹æ•°æ®éªŒè¯å¤±è´¥: {'; '.join(validation_result['errors'])}"
                                errors.append(error_msg)
                                logger.warning(error_msg)
                                continue

                        # æ•°æ®æ¸…ç†å’Œæ ‡å‡†åŒ–
                        cleaned_test_case_data = await self.clean_and_normalize_test_case_data(test_case_data)

                        # è½¬æ¢ä¸ºæ•°æ®åº“åˆ›å»ºè¯·æ±‚
                        create_request = await self._convert_to_create_request(cleaned_test_case_data, message)

                        # ä¿å­˜åˆ°æ•°æ®åº“
                        saved_test_case = await self.test_case_repository.create_test_case(
                            session,
                            create_request
                        )

                        # ä¿å­˜æµ‹è¯•ç”¨ä¾‹ä¸éœ€æ±‚çš„å…³è”å…³ç³»
                        await self._save_test_case_requirements(
                            session, saved_test_case.id, cleaned_test_case_data, message
                        )

                        # è®°å½•æˆåŠŸä¿å­˜çš„æµ‹è¯•ç”¨ä¾‹
                        saved_test_case_info = {
                            "id": saved_test_case.id,
                            "title": saved_test_case.title,
                            "test_type": saved_test_case.test_type.value,
                            "test_level": saved_test_case.test_level.value,
                            "priority": saved_test_case.priority.value,
                            "status": saved_test_case.status.value,
                            "created_at": saved_test_case.created_at.isoformat() if saved_test_case.created_at else None,
                            "ai_confidence": saved_test_case.ai_confidence,
                            "input_source": saved_test_case.input_source.value if saved_test_case.input_source else None
                        }
                        saved_test_cases.append(saved_test_case_info)

                        logger.info(f"æˆåŠŸä¿å­˜æµ‹è¯•ç”¨ä¾‹: {saved_test_case.title}")

                        # æŒ‰é…ç½®çš„é—´éš”æäº¤
                        if (i + 1) % self.save_config["commit_interval"] == 0:
                            await session.commit()

                    except Exception as e:
                        error_msg = f"ä¿å­˜ç¬¬ {global_index} ä¸ªæµ‹è¯•ç”¨ä¾‹å¤±è´¥: {str(e)}"
                        errors.append(error_msg)
                        logger.error(error_msg)

                        # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
                        await self._log_save_error(test_case_data, e, global_index)

                        # å¦‚æœå¯ç”¨é”™è¯¯å›æ»šï¼Œå›æ»šå½“å‰äº‹åŠ¡
                        if self.save_config["rollback_on_error"]:
                            await session.rollback()
                            break
                        continue

                # æœ€ç»ˆæäº¤
                await session.commit()

        except Exception as e:
            logger.error(f"æ‰¹æ¬¡ä¿å­˜å¼‚å¸¸: {str(e)}")
            errors.append(f"æ‰¹æ¬¡ä¿å­˜å¼‚å¸¸: {str(e)}")

        return {
            "saved_test_cases": saved_test_cases,
            "errors": errors
        }

    async def _validate_project_id(self, project_id: Optional[str]) -> Optional[str]:
        """
        éªŒè¯é¡¹ç›®IDæ˜¯å¦å­˜åœ¨

        Args:
            project_id: é¡¹ç›®ID

        Returns:
            Optional[str]: æœ‰æ•ˆçš„é¡¹ç›®IDï¼Œå¦‚æœæ— æ•ˆåˆ™è¿”å›Noneä½¿ç”¨é»˜è®¤é¡¹ç›®
        """
        if not project_id or not project_id.strip():
            return None

        try:
            async with db_manager.get_session() as session:
                # æ£€æŸ¥é¡¹ç›®æ˜¯å¦å­˜åœ¨
                from sqlalchemy import text
                result = await session.execute(
                    text("SELECT COUNT(*) FROM projects WHERE id = :project_id"),
                    {"project_id": project_id.strip()}
                )

                if result.scalar() > 0:
                    return project_id.strip()
                else:
                    logger.warning(f"é¡¹ç›®IDä¸å­˜åœ¨: {project_id}ï¼Œå°†ä½¿ç”¨é»˜è®¤é¡¹ç›®")
                    return None

        except Exception as e:
            logger.error(f"éªŒè¯é¡¹ç›®IDå¤±è´¥: {str(e)}ï¼Œå°†ä½¿ç”¨é»˜è®¤é¡¹ç›®")
            return None

    def _normalize_string_field(self, field_value) -> Optional[str]:
        """
        æ ‡å‡†åŒ–å­—ç¬¦ä¸²å­—æ®µï¼Œå¤„ç†å¯èƒ½çš„åˆ—è¡¨ç±»å‹

        Args:
            field_value: å­—æ®µå€¼ï¼Œå¯èƒ½æ˜¯å­—ç¬¦ä¸²ã€åˆ—è¡¨æˆ–None

        Returns:
            Optional[str]: æ ‡å‡†åŒ–åçš„å­—ç¬¦ä¸²å€¼
        """
        if field_value is None:
            return None
        elif isinstance(field_value, list):
            # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œç”¨æ¢è¡Œç¬¦è¿æ¥
            return "\n".join(str(item) for item in field_value if item is not None)
        else:
            # å…¶ä»–ç±»å‹è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            return str(field_value)

    async def _convert_to_create_request(
        self,
        test_case_data: TestCaseData,
        message: TestCaseSaveRequest
    ) -> TestCaseCreateRequest:
        """è½¬æ¢æµ‹è¯•ç”¨ä¾‹æ•°æ®ä¸ºæ•°æ®åº“åˆ›å»ºè¯·æ±‚"""
        # ä½¿ç”¨è¾…åŠ©å‡½æ•°æ ‡å‡†åŒ–å­—ç¬¦ä¸²å­—æ®µ
        preconditions = self._normalize_string_field(test_case_data.preconditions)
        expected_results = self._normalize_string_field(test_case_data.expected_results)
        description = self._normalize_string_field(test_case_data.description)

        # éªŒè¯é¡¹ç›®ID - å¦‚æœä¸ºç©ºæˆ–æ— æ•ˆï¼Œä½¿ç”¨Noneè®©Repositoryå¤„ç†é»˜è®¤é¡¹ç›®
        project_id = await self._validate_project_id(message.project_id)

        return TestCaseCreateRequest(
            title=test_case_data.title,
            description=description,
            preconditions=preconditions,
            test_steps=test_case_data.test_steps,
            expected_results=expected_results,
            test_type=test_case_data.test_type,
            test_level=test_case_data.test_level,
            priority=test_case_data.priority,
            project_id=project_id,  # ä½¿ç”¨å¤„ç†åçš„é¡¹ç›®ID
            session_id=message.session_id,
            input_source=test_case_data.input_source,
            source_file_path=test_case_data.source_file_path,
            ai_generated=True,
            ai_confidence=test_case_data.ai_confidence,
            ai_model_info={
                "model": "deepseek-chat",
                "generation_time": datetime.now().isoformat(),
                "agent_version": "2.0",
                "session_id": message.session_id
            },
            tags=getattr(test_case_data, 'tags', None) or ["AIç”Ÿæˆ"]
        )

    async def get_test_cases_by_session(self, session_id: str) -> List[Dict[str, Any]]:
        """æ ¹æ®ä¼šè¯IDè·å–æµ‹è¯•ç”¨ä¾‹"""
        try:
            async with db_manager.get_session() as session:
                # ç›´æ¥æŸ¥è¯¢æŒ‡å®šä¼šè¯IDçš„æµ‹è¯•ç”¨ä¾‹
                from app.database.models.test_case import TestCase
                from sqlalchemy import select

                stmt = select(TestCase).where(TestCase.session_id == session_id)
                result = await session.execute(stmt)
                test_cases = result.scalars().all()

                # æ„å»ºè¿”å›æ•°æ®
                filtered_cases = []
                for test_case in test_cases:
                    filtered_cases.append({
                        "id": test_case.id,
                        "title": test_case.title,
                        "test_type": test_case.test_type.value,
                        "priority": test_case.priority.value,
                        "status": test_case.status.value,
                        "created_at": test_case.created_at.isoformat()
                    })

                return filtered_cases
                
        except Exception as e:
            logger.error(f"è·å–ä¼šè¯æµ‹è¯•ç”¨ä¾‹å¤±è´¥: {str(e)}")
            return []

    async def update_test_case_status_batch(
        self, 
        test_case_ids: List[str], 
        status: str,
        updated_by: str
    ) -> Dict[str, Any]:
        """æ‰¹é‡æ›´æ–°æµ‹è¯•ç”¨ä¾‹çŠ¶æ€"""
        try:
            async with db_manager.get_session() as session:
                success_count = 0
                failed_count = 0
                
                for test_case_id in test_case_ids:
                    try:
                        success = await self.test_case_repository.update_test_case_status(
                            session, test_case_id, status, updated_by
                        )
                        if success:
                            success_count += 1
                        else:
                            failed_count += 1
                    except Exception as e:
                        logger.error(f"æ›´æ–°æµ‹è¯•ç”¨ä¾‹ {test_case_id} çŠ¶æ€å¤±è´¥: {str(e)}")
                        failed_count += 1
                
                return {
                    "success_count": success_count,
                    "failed_count": failed_count,
                    "total_count": len(test_case_ids)
                }
                
        except Exception as e:
            logger.error(f"æ‰¹é‡æ›´æ–°æµ‹è¯•ç”¨ä¾‹çŠ¶æ€å¤±è´¥: {str(e)}")
            return {
                "success_count": 0,
                "failed_count": len(test_case_ids),
                "total_count": len(test_case_ids),
                "error": str(e)
            }

    def _update_average_processing_time(self, start_time: datetime):
        """æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´"""
        processing_time = (datetime.now() - start_time).total_seconds()
        current_avg = self.save_metrics["average_processing_time"]
        total_requests = self.save_metrics["total_requests"]

        # è®¡ç®—æ–°çš„å¹³å‡å€¼
        new_avg = ((current_avg * (total_requests - 1)) + processing_time) / total_requests
        self.save_metrics["average_processing_time"] = new_avg

    def get_performance_metrics(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        total_requests = max(self.save_metrics["total_requests"], 1)
        successful_saves = self.save_metrics["successful_saves"]

        return {
            **self.save_metrics,
            "success_rate": (successful_saves / total_requests) * 100,
            "average_batch_size": (
                sum(self.save_metrics["batch_sizes"]) /
                max(len(self.save_metrics["batch_sizes"]), 1)
            ),
            "average_test_cases_per_request": (
                self.save_metrics["total_test_cases_saved"] /
                max(successful_saves, 1)
            ),
            "agent_name": self.agent_name,
            "agent_id": self.id.key
        }

    def reset_metrics(self):
        """é‡ç½®æ€§èƒ½æŒ‡æ ‡"""
        self.save_metrics = {
            "total_requests": 0,
            "successful_saves": 0,
            "failed_saves": 0,
            "total_test_cases_saved": 0,
            "average_processing_time": 0.0,
            "batch_sizes": []
        }
        logger.info(f"å·²é‡ç½® {self.agent_name} çš„æ€§èƒ½æŒ‡æ ‡")

    def update_save_config(self, config_updates: Dict[str, Any]):
        """æ›´æ–°ä¿å­˜é…ç½®"""
        for key, value in config_updates.items():
            if key in self.save_config:
                old_value = self.save_config[key]
                self.save_config[key] = value
                logger.info(f"æ›´æ–°ä¿å­˜é…ç½® {key}: {old_value} â†’ {value}")
            else:
                logger.warning(f"æœªçŸ¥çš„é…ç½®é¡¹: {key}")

    def get_save_config(self) -> Dict[str, Any]:
        """è·å–å½“å‰ä¿å­˜é…ç½®"""
        return self.save_config.copy()

    async def validate_test_case_data(self, test_case_data: TestCaseData) -> Dict[str, Any]:
        """éªŒè¯æµ‹è¯•ç”¨ä¾‹æ•°æ®çš„å®Œæ•´æ€§å’Œæœ‰æ•ˆæ€§"""
        validation_result = {
            "is_valid": True,
            "errors": [],
            "warnings": [],
            "suggestions": []
        }

        # å¿…å¡«å­—æ®µéªŒè¯
        if not test_case_data.title or not test_case_data.title.strip():
            validation_result["is_valid"] = False
            validation_result["errors"].append("æµ‹è¯•ç”¨ä¾‹æ ‡é¢˜ä¸èƒ½ä¸ºç©º")

        # æ ‡é¢˜é•¿åº¦éªŒè¯
        if test_case_data.title and len(test_case_data.title) > 500:
            validation_result["is_valid"] = False
            validation_result["errors"].append("æµ‹è¯•ç”¨ä¾‹æ ‡é¢˜é•¿åº¦ä¸èƒ½è¶…è¿‡500å­—ç¬¦")

        # æµ‹è¯•æ­¥éª¤éªŒè¯
        if not test_case_data.test_steps:
            validation_result["warnings"].append("æµ‹è¯•æ­¥éª¤ä¸ºç©ºï¼Œå»ºè®®æ·»åŠ è¯¦ç»†çš„æµ‹è¯•æ­¥éª¤")
        elif isinstance(test_case_data.test_steps, list) and len(test_case_data.test_steps) == 0:
            validation_result["warnings"].append("æµ‹è¯•æ­¥éª¤åˆ—è¡¨ä¸ºç©º")

        # é¢„æœŸç»“æœéªŒè¯
        if not test_case_data.expected_results:
            validation_result["warnings"].append("é¢„æœŸç»“æœä¸ºç©ºï¼Œå»ºè®®æ·»åŠ æ˜ç¡®çš„é¢„æœŸç»“æœ")

        # æšä¸¾å€¼éªŒè¯
        try:
            if test_case_data.test_type not in [t.value for t in TestType]:
                validation_result["errors"].append(f"æ— æ•ˆçš„æµ‹è¯•ç±»å‹: {test_case_data.test_type}")
        except:
            validation_result["errors"].append("æµ‹è¯•ç±»å‹æ ¼å¼é”™è¯¯")

        try:
            if test_case_data.test_level not in [l.value for l in TestLevel]:
                validation_result["errors"].append(f"æ— æ•ˆçš„æµ‹è¯•çº§åˆ«: {test_case_data.test_level}")
        except:
            validation_result["errors"].append("æµ‹è¯•çº§åˆ«æ ¼å¼é”™è¯¯")

        try:
            if test_case_data.priority not in [p.value for p in Priority]:
                validation_result["errors"].append(f"æ— æ•ˆçš„ä¼˜å…ˆçº§: {test_case_data.priority}")
        except:
            validation_result["errors"].append("ä¼˜å…ˆçº§æ ¼å¼é”™è¯¯")

        # AIç½®ä¿¡åº¦éªŒè¯
        if hasattr(test_case_data, 'ai_confidence') and test_case_data.ai_confidence is not None:
            if not (0 <= test_case_data.ai_confidence <= 1):
                validation_result["warnings"].append("AIç½®ä¿¡åº¦åº”è¯¥åœ¨0-1ä¹‹é—´")

        # æä¾›æ”¹è¿›å»ºè®®
        if test_case_data.title and len(test_case_data.title) < 10:
            validation_result["suggestions"].append("å»ºè®®æµ‹è¯•ç”¨ä¾‹æ ‡é¢˜æ›´åŠ è¯¦ç»†å’Œæè¿°æ€§")

        if not test_case_data.description:
            validation_result["suggestions"].append("å»ºè®®æ·»åŠ æµ‹è¯•ç”¨ä¾‹æè¿°ä»¥æé«˜å¯è¯»æ€§")

        return validation_result

    async def clean_and_normalize_test_case_data(self, test_case_data: TestCaseData) -> TestCaseData:
        """æ¸…ç†å’Œæ ‡å‡†åŒ–æµ‹è¯•ç”¨ä¾‹æ•°æ®"""
        try:
            # æ¸…ç†æ ‡é¢˜
            if test_case_data.title:
                test_case_data.title = test_case_data.title.strip()
                # ç§»é™¤å¤šä½™çš„ç©ºæ ¼
                test_case_data.title = ' '.join(test_case_data.title.split())

            # æ¸…ç†æè¿°
            if test_case_data.description:
                test_case_data.description = test_case_data.description.strip()

            # æ¸…ç†å‰ç½®æ¡ä»¶
            if test_case_data.preconditions:
                test_case_data.preconditions = self._normalize_string_field(test_case_data.preconditions)

            # æ¸…ç†é¢„æœŸç»“æœ
            if test_case_data.expected_results:
                test_case_data.expected_results = self._normalize_string_field(test_case_data.expected_results)

            # æ ‡å‡†åŒ–æµ‹è¯•æ­¥éª¤
            if test_case_data.test_steps:
                test_case_data.test_steps = await self._normalize_test_steps(test_case_data.test_steps)

            # æ ‡å‡†åŒ–æ ‡ç­¾
            if hasattr(test_case_data, 'tags') and test_case_data.tags:
                test_case_data.tags = self._normalize_tags(test_case_data.tags)

            return test_case_data

        except Exception as e:
            logger.warning(f"æ¸…ç†æµ‹è¯•ç”¨ä¾‹æ•°æ®å¤±è´¥: {str(e)}")
            return test_case_data

    async def _normalize_test_steps(self, test_steps) -> List[Dict[str, Any]]:
        """æ ‡å‡†åŒ–æµ‹è¯•æ­¥éª¤æ ¼å¼"""
        if not test_steps:
            return []

        normalized_steps = []

        if isinstance(test_steps, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼ŒæŒ‰è¡Œåˆ†å‰²
            lines = test_steps.split('\n')
            for i, line in enumerate(lines, 1):
                if line.strip():
                    normalized_steps.append({
                        "step_number": i,
                        "action": line.strip(),
                        "data": "",
                        "expected": ""
                    })
        elif isinstance(test_steps, list):
            for i, step in enumerate(test_steps, 1):
                if isinstance(step, dict):
                    # ç¡®ä¿åŒ…å«å¿…è¦å­—æ®µ
                    normalized_step = {
                        "step_number": step.get("step_number", i),
                        "action": step.get("action", ""),
                        "data": step.get("data", ""),
                        "expected": step.get("expected", "")
                    }
                    normalized_steps.append(normalized_step)
                elif isinstance(step, str):
                    normalized_steps.append({
                        "step_number": i,
                        "action": step.strip(),
                        "data": "",
                        "expected": ""
                    })

        return normalized_steps

    def _normalize_tags(self, tags) -> List[str]:
        """æ ‡å‡†åŒ–æ ‡ç­¾"""
        if not tags:
            return []

        normalized_tags = []

        if isinstance(tags, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼ŒæŒ‰é€—å·åˆ†å‰²
            tag_list = tags.split(',')
            for tag in tag_list:
                clean_tag = tag.strip()
                if clean_tag and clean_tag not in normalized_tags:
                    normalized_tags.append(clean_tag)
        elif isinstance(tags, list):
            for tag in tags:
                clean_tag = str(tag).strip()
                if clean_tag and clean_tag not in normalized_tags:
                    normalized_tags.append(clean_tag)

        return normalized_tags[:10]  # é™åˆ¶æœ€å¤š10ä¸ªæ ‡ç­¾

    async def validate_test_case_data(self, test_case_data: TestCaseData) -> Dict[str, Any]:
        """éªŒè¯æµ‹è¯•ç”¨ä¾‹æ•°æ®çš„å®Œæ•´æ€§å’Œæœ‰æ•ˆæ€§"""
        validation_result = {
            "is_valid": True,
            "errors": [],
            "warnings": [],
            "suggestions": []
        }

        # å¿…å¡«å­—æ®µéªŒè¯
        if not test_case_data.title or not test_case_data.title.strip():
            validation_result["is_valid"] = False
            validation_result["errors"].append("æµ‹è¯•ç”¨ä¾‹æ ‡é¢˜ä¸èƒ½ä¸ºç©º")

        # æ ‡é¢˜é•¿åº¦éªŒè¯
        if test_case_data.title and len(test_case_data.title) > 500:
            validation_result["is_valid"] = False
            validation_result["errors"].append("æµ‹è¯•ç”¨ä¾‹æ ‡é¢˜é•¿åº¦ä¸èƒ½è¶…è¿‡500å­—ç¬¦")

        # æµ‹è¯•æ­¥éª¤éªŒè¯
        if not test_case_data.test_steps:
            validation_result["warnings"].append("æµ‹è¯•æ­¥éª¤ä¸ºç©ºï¼Œå»ºè®®æ·»åŠ è¯¦ç»†çš„æµ‹è¯•æ­¥éª¤")
        elif isinstance(test_case_data.test_steps, list) and len(test_case_data.test_steps) == 0:
            validation_result["warnings"].append("æµ‹è¯•æ­¥éª¤åˆ—è¡¨ä¸ºç©º")

        # é¢„æœŸç»“æœéªŒè¯
        if not test_case_data.expected_results:
            validation_result["warnings"].append("é¢„æœŸç»“æœä¸ºç©ºï¼Œå»ºè®®æ·»åŠ æ˜ç¡®çš„é¢„æœŸç»“æœ")

        # æšä¸¾å€¼éªŒè¯
        try:
            if test_case_data.test_type not in [t.value for t in TestType]:
                validation_result["errors"].append(f"æ— æ•ˆçš„æµ‹è¯•ç±»å‹: {test_case_data.test_type}")
        except:
            validation_result["errors"].append("æµ‹è¯•ç±»å‹æ ¼å¼é”™è¯¯")

        try:
            if test_case_data.test_level not in [l.value for l in TestLevel]:
                validation_result["errors"].append(f"æ— æ•ˆçš„æµ‹è¯•çº§åˆ«: {test_case_data.test_level}")
        except:
            validation_result["errors"].append("æµ‹è¯•çº§åˆ«æ ¼å¼é”™è¯¯")

        try:
            if test_case_data.priority not in [p.value for p in Priority]:
                validation_result["errors"].append(f"æ— æ•ˆçš„ä¼˜å…ˆçº§: {test_case_data.priority}")
        except:
            validation_result["errors"].append("ä¼˜å…ˆçº§æ ¼å¼é”™è¯¯")

        # AIç½®ä¿¡åº¦éªŒè¯
        if hasattr(test_case_data, 'ai_confidence') and test_case_data.ai_confidence is not None:
            if not (0 <= test_case_data.ai_confidence <= 1):
                validation_result["warnings"].append("AIç½®ä¿¡åº¦åº”è¯¥åœ¨0-1ä¹‹é—´")

        # æä¾›æ”¹è¿›å»ºè®®
        if test_case_data.title and len(test_case_data.title) < 10:
            validation_result["suggestions"].append("å»ºè®®æµ‹è¯•ç”¨ä¾‹æ ‡é¢˜æ›´åŠ è¯¦ç»†å’Œæè¿°æ€§")

        if not test_case_data.description:
            validation_result["suggestions"].append("å»ºè®®æ·»åŠ æµ‹è¯•ç”¨ä¾‹æè¿°ä»¥æé«˜å¯è¯»æ€§")

        return validation_result

    async def clean_and_normalize_test_case_data(self, test_case_data: TestCaseData) -> TestCaseData:
        """æ¸…ç†å’Œæ ‡å‡†åŒ–æµ‹è¯•ç”¨ä¾‹æ•°æ®"""
        try:
            # æ¸…ç†æ ‡é¢˜
            if test_case_data.title:
                test_case_data.title = test_case_data.title.strip()
                # ç§»é™¤å¤šä½™çš„ç©ºæ ¼
                test_case_data.title = ' '.join(test_case_data.title.split())

            # æ¸…ç†æè¿°
            if test_case_data.description:
                test_case_data.description = test_case_data.description.strip()

            # æ¸…ç†å‰ç½®æ¡ä»¶
            if test_case_data.preconditions:
                test_case_data.preconditions = self._normalize_string_field(test_case_data.preconditions)

            # æ¸…ç†é¢„æœŸç»“æœ
            if test_case_data.expected_results:
                test_case_data.expected_results = self._normalize_string_field(test_case_data.expected_results)

            # æ ‡å‡†åŒ–æµ‹è¯•æ­¥éª¤
            if test_case_data.test_steps:
                test_case_data.test_steps = await self._normalize_test_steps(test_case_data.test_steps)

            # æ ‡å‡†åŒ–æ ‡ç­¾
            if hasattr(test_case_data, 'tags') and test_case_data.tags:
                test_case_data.tags = self._normalize_tags(test_case_data.tags)

            return test_case_data

        except Exception as e:
            logger.warning(f"æ¸…ç†æµ‹è¯•ç”¨ä¾‹æ•°æ®å¤±è´¥: {str(e)}")
            return test_case_data

    async def _normalize_test_steps(self, test_steps) -> List[Dict[str, Any]]:
        """æ ‡å‡†åŒ–æµ‹è¯•æ­¥éª¤æ ¼å¼"""
        if not test_steps:
            return []

        normalized_steps = []

        if isinstance(test_steps, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼ŒæŒ‰è¡Œåˆ†å‰²
            lines = test_steps.split('\n')
            for i, line in enumerate(lines, 1):
                if line.strip():
                    normalized_steps.append({
                        "step_number": i,
                        "action": line.strip(),
                        "data": "",
                        "expected": ""
                    })
        elif isinstance(test_steps, list):
            for i, step in enumerate(test_steps, 1):
                if isinstance(step, dict):
                    # ç¡®ä¿åŒ…å«å¿…è¦å­—æ®µ
                    normalized_step = {
                        "step_number": step.get("step_number", i),
                        "action": step.get("action", ""),
                        "data": step.get("data", ""),
                        "expected": step.get("expected", "")
                    }
                    normalized_steps.append(normalized_step)
                elif isinstance(step, str):
                    normalized_steps.append({
                        "step_number": i,
                        "action": step.strip(),
                        "data": "",
                        "expected": ""
                    })

        return normalized_steps

    def _normalize_tags(self, tags) -> List[str]:
        """æ ‡å‡†åŒ–æ ‡ç­¾"""
        if not tags:
            return []

        normalized_tags = []

        if isinstance(tags, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼ŒæŒ‰é€—å·åˆ†å‰²
            tag_list = tags.split(',')
            for tag in tag_list:
                clean_tag = tag.strip()
                if clean_tag and clean_tag not in normalized_tags:
                    normalized_tags.append(clean_tag)
        elif isinstance(tags, list):
            for tag in tags:
                clean_tag = str(tag).strip()
                if clean_tag and clean_tag not in normalized_tags:
                    normalized_tags.append(clean_tag)

        return normalized_tags[:10]  # é™åˆ¶æœ€å¤š10ä¸ªæ ‡ç­¾

    async def _save_test_case_requirements(
        self,
        session,
        test_case_id: str,
        test_case_data: TestCaseData,
        message: TestCaseSaveRequest
    ) -> None:
        """ä¿å­˜æµ‹è¯•ç”¨ä¾‹ä¸éœ€æ±‚çš„å…³è”å…³ç³»"""
        try:
            # ä»æµ‹è¯•ç”¨ä¾‹æ•°æ®ä¸­æå–éœ€æ±‚å…³è”ä¿¡æ¯
            requirement_ids = []

            # æ–¹æ³•1: ä»source_metadataä¸­è·å–éœ€æ±‚ID
            if hasattr(test_case_data, 'source_metadata') and test_case_data.source_metadata:
                if 'requirement_id' in test_case_data.source_metadata:
                    requirement_ids.append(test_case_data.source_metadata['requirement_id'])
                elif 'requirement_ids' in test_case_data.source_metadata:
                    requirement_ids.extend(test_case_data.source_metadata['requirement_ids'])

            # æ–¹æ³•2: ä»messageçš„requirement_mappingsä¸­è·å–
            if message.requirement_mappings:
                test_case_title = test_case_data.title
                if test_case_title in message.requirement_mappings:
                    requirement_ids.extend(message.requirement_mappings[test_case_title])

            # æ–¹æ³•3: æ ¹æ®ä¼šè¯IDæŸ¥æ‰¾ç›¸å…³éœ€æ±‚
            if not requirement_ids and message.session_id:
                session_requirements = await self.requirement_repository.get_requirements_by_session(
                    session, message.session_id
                )
                # å¦‚æœæ‰¾åˆ°éœ€æ±‚ï¼Œå»ºç«‹å…³è”ï¼ˆç®€å•ç­–ç•¥ï¼šå…³è”æ‰€æœ‰åŒä¼šè¯çš„éœ€æ±‚ï¼‰
                requirement_ids = [req.id for req in session_requirements]

            # æ–¹æ³•4: æ™ºèƒ½åŒ¹é…éœ€æ±‚ï¼ˆåŸºäºå…³é”®è¯åŒ¹é…ï¼‰
            if not requirement_ids:
                requirement_ids = await self._smart_match_requirements(
                    session, test_case_data, message
                )

            # å»é‡å¹¶éªŒè¯éœ€æ±‚ID
            requirement_ids = await self._validate_requirement_ids(session, requirement_ids)

            # ä¿å­˜å…³è”å…³ç³»
            if requirement_ids:
                await self.send_response(
                    f"ğŸ”— æ­£åœ¨å…³è” {len(requirement_ids)} ä¸ªéœ€æ±‚åˆ°æµ‹è¯•ç”¨ä¾‹..."
                )

                await self.test_case_requirement_repository.batch_create_test_case_requirements(
                    session,
                    test_case_id,
                    requirement_ids,
                    coverage_type="full"
                )

                logger.info(f"æˆåŠŸå…³è” {len(requirement_ids)} ä¸ªéœ€æ±‚åˆ°æµ‹è¯•ç”¨ä¾‹ {test_case_id}")
            else:
                logger.info(f"æµ‹è¯•ç”¨ä¾‹ {test_case_id} æ²¡æœ‰æ‰¾åˆ°ç›¸å…³éœ€æ±‚è¿›è¡Œå…³è”")

        except Exception as e:
            logger.error(f"ä¿å­˜æµ‹è¯•ç”¨ä¾‹éœ€æ±‚å…³è”å¤±è´¥: {str(e)}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“æµ‹è¯•ç”¨ä¾‹çš„ä¿å­˜

    async def _smart_match_requirements(
        self,
        session,
        test_case_data: TestCaseData,
        message: TestCaseSaveRequest
    ) -> List[str]:
        """æ™ºèƒ½åŒ¹é…ç›¸å…³éœ€æ±‚"""
        try:
            # æå–æµ‹è¯•ç”¨ä¾‹å…³é”®è¯
            keywords = self._extract_keywords_from_test_case(test_case_data)

            if not keywords:
                return []

            # æœç´¢åŒ¹é…çš„éœ€æ±‚
            matched_requirements = await self.requirement_repository.search_requirements_by_keywords(
                session, keywords, message.project_id
            )

            return [req.id for req in matched_requirements[:5]]  # æœ€å¤šå…³è”5ä¸ªéœ€æ±‚

        except Exception as e:
            logger.warning(f"æ™ºèƒ½åŒ¹é…éœ€æ±‚å¤±è´¥: {str(e)}")
            return []

    def _extract_keywords_from_test_case(self, test_case_data: TestCaseData) -> List[str]:
        """ä»æµ‹è¯•ç”¨ä¾‹ä¸­æå–å…³é”®è¯"""
        keywords = []

        # ä»æ ‡é¢˜ä¸­æå–å…³é”®è¯
        if test_case_data.title:
            title_words = test_case_data.title.split()
            keywords.extend([word for word in title_words if len(word) > 2])

        # ä»æè¿°ä¸­æå–å…³é”®è¯
        if test_case_data.description:
            desc_words = test_case_data.description.split()
            keywords.extend([word for word in desc_words if len(word) > 2])

        # å»é‡å¹¶è¿”å›å‰10ä¸ªå…³é”®è¯
        return list(set(keywords))[:10]

    async def _validate_requirement_ids(self, session, requirement_ids: List[str]) -> List[str]:
        """éªŒè¯éœ€æ±‚IDçš„æœ‰æ•ˆæ€§"""
        if not requirement_ids:
            return []

        try:
            # å»é‡
            unique_ids = list(set(requirement_ids))

            # éªŒè¯éœ€æ±‚æ˜¯å¦å­˜åœ¨
            valid_ids = []
            for req_id in unique_ids:
                if await self.requirement_repository.requirement_exists(session, req_id):
                    valid_ids.append(req_id)
                else:
                    logger.warning(f"éœ€æ±‚IDä¸å­˜åœ¨: {req_id}")

            return valid_ids

        except Exception as e:
            logger.error(f"éªŒè¯éœ€æ±‚IDå¤±è´¥: {str(e)}")
            return []

    async def _log_save_error(self, test_case_data: TestCaseData, error: Exception, index: int):
        """è®°å½•ä¿å­˜é”™è¯¯çš„è¯¦ç»†ä¿¡æ¯"""
        try:
            error_info = {
                "index": index,
                "title": test_case_data.title,
                "test_type": test_case_data.test_type,
                "error_type": type(error).__name__,
                "error_message": str(error),
                "timestamp": datetime.now().isoformat()
            }

            # è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
            logger.error(f"æµ‹è¯•ç”¨ä¾‹ä¿å­˜é”™è¯¯è¯¦æƒ…: {json.dumps(error_info, ensure_ascii=False, indent=2)}")

        except Exception as e:
            logger.error(f"è®°å½•ä¿å­˜é”™è¯¯å¤±è´¥: {str(e)}")

    async def get_save_statistics(self, session_id: Optional[str] = None) -> Dict[str, Any]:
        """è·å–ä¿å­˜ç»Ÿè®¡ä¿¡æ¯"""
        try:
            async with db_manager.get_session() as session:
                from app.database.models.test_case import TestCase
                from sqlalchemy import select, func

                # æ€»æ•°ç»Ÿè®¡
                total_count_query = select(func.count(TestCase.id))
                if session_id:
                    total_count_query = total_count_query.where(TestCase.session_id == session_id)

                total_result = await session.execute(total_count_query)
                total_count = total_result.scalar()

                # AIç”Ÿæˆç»Ÿè®¡
                ai_generated_query = select(func.count(TestCase.id)).where(
                    TestCase.ai_generated == True
                )
                if session_id:
                    ai_generated_query = ai_generated_query.where(TestCase.session_id == session_id)

                ai_result = await session.execute(ai_generated_query)
                ai_generated_count = ai_result.scalar()

                return {
                    "total_count": total_count,
                    "ai_generated_count": ai_generated_count,
                    "manual_count": total_count - ai_generated_count,
                    "session_id": session_id,
                    "generated_at": datetime.now().isoformat()
                }

        except Exception as e:
            logger.error(f"è·å–ä¿å­˜ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {
                "error": str(e),
                "generated_at": datetime.now().isoformat()
            }

    async def _log_save_error(self, test_case_data: TestCaseData, error: Exception, index: int):
        """è®°å½•ä¿å­˜é”™è¯¯çš„è¯¦ç»†ä¿¡æ¯"""
        try:
            error_info = {
                "index": index,
                "title": test_case_data.title,
                "test_type": test_case_data.test_type,
                "error_type": type(error).__name__,
                "error_message": str(error),
                "timestamp": datetime.now().isoformat()
            }

            # è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
            logger.error(f"æµ‹è¯•ç”¨ä¾‹ä¿å­˜é”™è¯¯è¯¦æƒ…: {json.dumps(error_info, ensure_ascii=False, indent=2)}")

        except Exception as e:
            logger.error(f"è®°å½•ä¿å­˜é”™è¯¯å¤±è´¥: {str(e)}")

    async def get_save_statistics(self, session_id: Optional[str] = None) -> Dict[str, Any]:
        """è·å–ä¿å­˜ç»Ÿè®¡ä¿¡æ¯"""
        try:
            async with db_manager.get_session() as session:
                from app.database.models.test_case import TestCase
                from sqlalchemy import select, func

                # åŸºç¡€æŸ¥è¯¢
                base_query = select(TestCase)
                if session_id:
                    base_query = base_query.where(TestCase.session_id == session_id)

                # æ€»æ•°ç»Ÿè®¡
                total_count_query = select(func.count(TestCase.id))
                if session_id:
                    total_count_query = total_count_query.where(TestCase.session_id == session_id)

                total_result = await session.execute(total_count_query)
                total_count = total_result.scalar()

                # æŒ‰çŠ¶æ€ç»Ÿè®¡
                status_query = select(
                    TestCase.status,
                    func.count(TestCase.id).label('count')
                ).group_by(TestCase.status)

                if session_id:
                    status_query = status_query.where(TestCase.session_id == session_id)

                status_result = await session.execute(status_query)
                status_stats = {row.status.value: row.count for row in status_result}

                # AIç”Ÿæˆç»Ÿè®¡
                ai_generated_query = select(func.count(TestCase.id)).where(
                    TestCase.ai_generated == True
                )
                if session_id:
                    ai_generated_query = ai_generated_query.where(TestCase.session_id == session_id)

                ai_result = await session.execute(ai_generated_query)
                ai_generated_count = ai_result.scalar()

                return {
                    "total_count": total_count,
                    "ai_generated_count": ai_generated_count,
                    "manual_count": total_count - ai_generated_count,
                    "status_distribution": status_stats,
                    "session_id": session_id,
                    "generated_at": datetime.now().isoformat()
                }

        except Exception as e:
            logger.error(f"è·å–ä¿å­˜ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {
                "error": str(e),
                "generated_at": datetime.now().isoformat()
            }
