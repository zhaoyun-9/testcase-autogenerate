"""
æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ™ºèƒ½ä½“ - å…¨é¢ä¼˜åŒ–ç‰ˆæœ¬
ä¸“æ³¨äºæµ‹è¯•ç”¨ä¾‹çš„ç”Ÿæˆé€»è¾‘ï¼Œé€šè¿‡æ¶ˆæ¯æœºåˆ¶ä¸å…¶ä»–æ™ºèƒ½ä½“åä½œ
éµå¾ªå•ä¸€èŒè´£åŸåˆ™ï¼Œå‚è€ƒ examples/agents/factory.py å’Œ examples/base.py çš„è®¾è®¡æ¨¡å¼
"""
import uuid
import json
from typing import Dict, List, Any, Optional
from datetime import datetime

from autogen_agentchat.base import TaskResult
from autogen_agentchat.messages import ModelClientStreamingChunkEvent
from autogen_core import message_handler, type_subscription, MessageContext, TopicId, AgentId
from loguru import logger
from pydantic import BaseModel, Field

from app.core.agents.base import BaseAgent
from app.core.types import TopicTypes, AgentTypes, AGENT_NAMES
from app.core.messages.test_case import (
    TestCaseGenerationRequest, TestCaseGenerationResponse,
    TestCaseData, MindMapGenerationRequest
)
from app.core.enums import (
    TestType, TestLevel, Priority, TestCaseStatus, InputSource
)
from app.agents.database.test_case_saver_agent import TestCaseSaveRequest, TestCaseSaveResponse


class TestCaseGenerationResult(BaseModel):
    """æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆç»“æœ"""
    generated_count: int = Field(0, description="ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹æ•°é‡")
    generated_test_cases: List[TestCaseData] = Field(default_factory=list, description="ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹æ•°æ®")
    processing_time: float = Field(0.0, description="å¤„ç†æ—¶é—´")
    errors: List[str] = Field(default_factory=list, description="é”™è¯¯ä¿¡æ¯")


@type_subscription(topic_type=TopicTypes.TEST_CASE_GENERATOR.value)
class TestCaseGeneratorAgent(BaseAgent):
    """
    æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ™ºèƒ½ä½“ - ä¼˜åŒ–ç‰ˆæœ¬
    
    èŒè´£ï¼š
    1. æ¥æ”¶æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆè¯·æ±‚
    2. ç”Ÿæˆå’Œå¢å¼ºæµ‹è¯•ç”¨ä¾‹
    3. é€šè¿‡æ¶ˆæ¯æœºåˆ¶åè°ƒä¿å­˜å’Œæ€ç»´å¯¼å›¾ç”Ÿæˆ
    4. ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œå“åº”æœºåˆ¶
    
    è®¾è®¡åŸåˆ™ï¼š
    - å•ä¸€èŒè´£ï¼šåªè´Ÿè´£æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ
    - æ¶ˆæ¯é©±åŠ¨ï¼šé€šè¿‡AutoGenæ¶ˆæ¯æœºåˆ¶ä¸å…¶ä»–æ™ºèƒ½ä½“é€šä¿¡
    - é”™è¯¯å¤„ç†ï¼šç»Ÿä¸€çš„å¼‚å¸¸å¤„ç†å’Œå“åº”æœºåˆ¶
    - æ€§èƒ½ç›‘æ§ï¼šè®°å½•ç”ŸæˆæŒ‡æ ‡å’Œæ€§èƒ½æ•°æ®
    """

    def __init__(self, model_client_instance=None, **kwargs):
        """åˆå§‹åŒ–æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ™ºèƒ½ä½“"""
        super().__init__(
            agent_id=AgentTypes.TEST_CASE_GENERATOR.value,
            agent_name=AGENT_NAMES.get(AgentTypes.TEST_CASE_GENERATOR.value, "æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ™ºèƒ½ä½“"),
            model_client_instance=model_client_instance,
            **kwargs
        )
        
        # åˆå§‹åŒ–æ€§èƒ½æŒ‡æ ‡
        self.generation_metrics = {
            "total_requests": 0,
            "successful_generations": 0,
            "failed_generations": 0,
            "average_processing_time": 0.0,
            "total_test_cases_generated": 0
        }
        
        # åˆå§‹åŒ–AIå¢å¼ºé…ç½®
        self.ai_enhancement_config = {
            "enabled": True,
            "model_type": "deepseek",
            "stream_enabled": False,
            "max_retries": 3
        }

        logger.info(f"æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ: {self.agent_name}")

    @message_handler
    async def handle_test_case_generation_request(
        self,
        message: TestCaseGenerationRequest,
        ctx: MessageContext
    ) -> None:
        """
        å¤„ç†æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆè¯·æ±‚ - ä¼˜åŒ–ç‰ˆæœ¬
        
        æµç¨‹ï¼š
        1. ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
        2. å‘é€ä¿å­˜è¯·æ±‚åˆ°æ•°æ®åº“æ™ºèƒ½ä½“
        3. å‘é€æ€ç»´å¯¼å›¾ç”Ÿæˆè¯·æ±‚ï¼ˆå¦‚æœéœ€è¦ï¼‰
        4. ç»Ÿä¸€å“åº”å¤„ç†
        """
        start_time = datetime.now()
        self.generation_metrics["total_requests"] += 1
        
        try:
            logger.info(f"å¼€å§‹å¤„ç†æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆè¯·æ±‚: {message.session_id}")

            # å‘é€å¼€å§‹å¤„ç†æ¶ˆæ¯
            await self.send_response(
                f"ğŸ”§ å¼€å§‹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼Œæ¥æº: {message.source_type}",
                region="process"
            )

            # å‘é€è¾“å…¥æ•°æ®ç»Ÿè®¡
            source_data_size = len(str(message.source_data)) if message.source_data else 0
            await self.send_response(
                f"ğŸ“Š è¾“å…¥æ•°æ®ç»Ÿè®¡: æ•°æ®å¤§å° {source_data_size} å­—ç¬¦, é…ç½®é¡¹ {len(message.generation_config)} ä¸ª",
                region="info",
                result={
                    "source_data_size": source_data_size,
                    "config_count": len(message.generation_config),
                    "source_type": message.source_type
                }
            )

            # æ­¥éª¤1: ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
            await self.send_response("ğŸ”„ ç¬¬1æ­¥: å¼€å§‹AIæ™ºèƒ½ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...", region="progress")
            generation_result = await self._generate_test_cases(message)

            if generation_result.generated_count == 0:
                await self.send_response("âš ï¸ æœªèƒ½ç”Ÿæˆä»»ä½•æµ‹è¯•ç”¨ä¾‹", region="warning")
                await self._handle_empty_generation(message, generation_result)
                return

            # å‘é€ç”Ÿæˆç»“æœç»Ÿè®¡
            await self.send_response(
                f"âœ… æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆ: å…±ç”Ÿæˆ {generation_result.generated_count} ä¸ªæµ‹è¯•ç”¨ä¾‹",
                region="success",
                result={
                    "generated_count": generation_result.generated_count,
                    "generation_time": generation_result.processing_time
                }
            )

            # æ­¥éª¤2: é€šè¿‡æ¶ˆæ¯æœºåˆ¶ä¿å­˜æµ‹è¯•ç”¨ä¾‹
            await self.send_response("ğŸ”„ ç¬¬2æ­¥: ä¿å­˜æµ‹è¯•ç”¨ä¾‹åˆ°æ•°æ®åº“...", region="progress")
            save_result = await self._send_save_request(message, generation_result)

            # å‘é€ä¿å­˜ç»“æœ
            if save_result.success:
                await self.send_response(
                    f"âœ… æ•°æ®åº“ä¿å­˜å®Œæˆ: æˆåŠŸä¿å­˜ {save_result.saved_count} ä¸ªæµ‹è¯•ç”¨ä¾‹",
                    region="success",
                    result={"saved_count": save_result.saved_count}
                )
            else:
                await self.send_response(
                    f"âš ï¸ æ•°æ®åº“ä¿å­˜éƒ¨åˆ†å¤±è´¥: æˆåŠŸ {save_result.saved_count} ä¸ª, å¤±è´¥ {save_result.failed_count} ä¸ª",
                    region="warning",
                    result={
                        "saved_count": save_result.saved_count,
                        "failed_count": save_result.failed_count
                    }
                )

            # æ­¥éª¤3: ç”Ÿæˆæ€ç»´å¯¼å›¾ï¼ˆå¦‚æœéœ€è¦ï¼‰
            mind_map_generated = False
            if message.generation_config.get("generate_mind_map", False) and save_result.success:
                await self.send_response("ğŸ”„ ç¬¬3æ­¥: ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æ€ç»´å¯¼å›¾...", region="progress")
                await self._send_mind_map_request(message, save_result.saved_test_cases)
                mind_map_generated = True
                await self.send_response("âœ… æ€ç»´å¯¼å›¾ç”Ÿæˆå®Œæˆ", region="success")
            elif message.generation_config.get("generate_mind_map", False):
                await self.send_response("âš ï¸ è·³è¿‡æ€ç»´å¯¼å›¾ç”Ÿæˆï¼ˆæ•°æ®åº“ä¿å­˜å¤±è´¥ï¼‰", region="warning")

            # æ­¥éª¤4: å‘é€æœ€ç»ˆå“åº”
            await self._send_final_response(
                message, generation_result, save_result, mind_map_generated, start_time
            )
            
            # æ›´æ–°æˆåŠŸæŒ‡æ ‡
            self.generation_metrics["successful_generations"] += 1
            self.generation_metrics["total_test_cases_generated"] += generation_result.generated_count
            self._update_average_processing_time(start_time)
            
        except Exception as e:
            await self._handle_generation_error(message, e, start_time)
            self.generation_metrics["failed_generations"] += 1

    async def _generate_test_cases(
        self,
        message: TestCaseGenerationRequest
    ) -> TestCaseGenerationResult:
        """ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼ˆæ ¸å¿ƒé€»è¾‘ï¼‰"""
        try:
            start_time = datetime.now()
            result = TestCaseGenerationResult()

            await self.send_response(
                "ğŸ“ æ­£åœ¨åˆ†æè¾“å…¥æ•°æ®å¹¶å‡†å¤‡ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...",
                region="progress"
            )

            # å¤„ç†æµ‹è¯•ç”¨ä¾‹æ•°æ®
            data_processing_start = datetime.now()
            processed_test_cases = await self._process_test_case_data(message)
            data_processing_time = (datetime.now() - data_processing_start).total_seconds()

            await self.send_response(
                f"âœ… æ•°æ®å¤„ç†å®Œæˆ: ç”Ÿæˆ {len(processed_test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹ (è€—æ—¶: {data_processing_time:.2f}ç§’)",
                region="success",
                result={
                    "generated_count": len(processed_test_cases),
                    "data_processing_time": data_processing_time
                }
            )

            # è®¡ç®—æ€»å¤„ç†æ—¶é—´
            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()

            # å‘é€æ€§èƒ½æŒ‡æ ‡
            if len(processed_test_cases) > 0:
                await self.send_response(
                    f"ğŸ“Š ç”Ÿæˆæ€§èƒ½æŒ‡æ ‡: å¹³å‡æ¯ä¸ªç”¨ä¾‹ {processing_time/len(processed_test_cases):.3f}ç§’",
                    region="info",
                    result={
                        "total_processing_time": processing_time,
                        "average_time_per_case": processing_time/len(processed_test_cases),
                        "generation_rate": len(processed_test_cases)/processing_time if processing_time > 0 else 0
                    }
                )

            result.generated_count = len(processed_test_cases)
            result.generated_test_cases = processed_test_cases
            result.processing_time = processing_time

            logger.info(f"æˆåŠŸç”Ÿæˆäº† {len(processed_test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
            return result

        except Exception as e:
            processing_time = (datetime.now() - start_time).total_seconds()
            logger.error(f"ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å¤±è´¥: {str(e)}")
            await self.send_response(
                f"âŒ æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥: {str(e)} (è€—æ—¶: {processing_time:.2f}ç§’)",
                region="error"
            )
            raise

    async def _process_test_case_data(
        self, 
        message: TestCaseGenerationRequest
    ) -> List[TestCaseData]:
        """å¤„ç†æµ‹è¯•ç”¨ä¾‹æ•°æ®"""
        try:
            processed_cases = []

            # å€ŸåŠ©RAGçŸ¥è¯†åº“ç³»ç»Ÿï¼Œè·å–å½“å‰ç”¨ä¾‹çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            i = 1
            for test_case_data in message.test_cases:
                # å¢å¼ºæµ‹è¯•ç”¨ä¾‹æ•°æ®
                await self.send_response(
                    f"ğŸ“ æ­£åœ¨å¢å¼ºç¬¬ {i} æ¡æµ‹è¯•ç”¨ä¾‹æ•°æ®...",
                    region="progress"
                )
                enhanced_case = await self._enhance_test_case(test_case_data, message)
                processed_cases.append(enhanced_case)
                i += 1
            
            return processed_cases
            
        except Exception as e:
            logger.error(f"å¤„ç†æµ‹è¯•ç”¨ä¾‹æ•°æ®å¤±è´¥: {str(e)}")
            raise

    async def _enhance_test_case(
        self, 
        test_case_data: TestCaseData, 
        message: TestCaseGenerationRequest
    ) -> TestCaseData:
        """å¢å¼ºæµ‹è¯•ç”¨ä¾‹æ•°æ®"""
        try:
            # å¦‚æœç¼ºå°‘è¯¦ç»†ä¿¡æ¯ï¼Œä½¿ç”¨AIç”Ÿæˆ
            if not test_case_data.test_steps or not test_case_data.expected_results:
                enhanced_data = await self._ai_enhance_test_case(test_case_data, message)
                
                # æ›´æ–°æµ‹è¯•ç”¨ä¾‹æ•°æ®
                if enhanced_data.get("test_steps"):
                    test_case_data.test_steps = enhanced_data["test_steps"]
                if enhanced_data.get("expected_results"):
                    test_case_data.expected_results = enhanced_data["expected_results"]
                if enhanced_data.get("preconditions"):
                    test_case_data.preconditions = enhanced_data["preconditions"]
            
            return test_case_data
            
        except Exception as e:
            logger.warning(f"å¢å¼ºæµ‹è¯•ç”¨ä¾‹å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®: {str(e)}")
            return test_case_data

    async def _ai_enhance_test_case(
        self, 
        test_case_data: TestCaseData, 
        message: TestCaseGenerationRequest
    ) -> Dict[str, Any]:
        """ä½¿ç”¨AIå¢å¼ºæµ‹è¯•ç”¨ä¾‹"""
        try:
            if not self.ai_enhancement_config["enabled"]:
                return {}
                
            # åˆ›å»ºAIå¢å¼ºæ™ºèƒ½ä½“
            agent = self._create_test_case_enhancer()
            
            # æ„å»ºå¢å¼ºæç¤º
            enhancement_prompt = self._build_enhancement_prompt(test_case_data, message)
            
            # æ‰§è¡ŒAIå¢å¼º
            enhancement_result = await self._run_ai_enhancement(agent, enhancement_prompt)

            return json.loads(enhancement_result.replace("```json", "").replace("```", ""))
            
        except Exception as e:
            logger.error(f"AIå¢å¼ºæµ‹è¯•ç”¨ä¾‹å¤±è´¥: {str(e)}")
            return {}

    def _create_test_case_enhancer(self):
        """åˆ›å»ºæµ‹è¯•ç”¨ä¾‹å¢å¼ºæ™ºèƒ½ä½“"""
        from app.agents.factory import agent_factory
        
        return agent_factory.create_assistant_agent(
            name="test_case_enhancer",
            system_message=self._build_enhancement_system_prompt(),
            model_client_type=self.ai_enhancement_config["model_type"],
            model_client_stream=self.ai_enhancement_config["stream_enabled"]
        )

    def _build_enhancement_system_prompt(self) -> str:
        """æ„å»ºå¢å¼ºç³»ç»Ÿæç¤º"""
        return """
ä½ æ˜¯ä¸“ä¸šçš„æµ‹è¯•ç”¨ä¾‹è®¾è®¡ä¸“å®¶ï¼Œæ“…é•¿å®Œå–„å’Œä¼˜åŒ–æµ‹è¯•ç”¨ä¾‹ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. æ ¹æ®æµ‹è¯•ç”¨ä¾‹æ ‡é¢˜å’Œæè¿°ï¼Œç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•æ­¥éª¤
2. è®¾è®¡åˆç†çš„å‰ç½®æ¡ä»¶
3. æ˜ç¡®é¢„æœŸç»“æœ
4. ç¡®ä¿æµ‹è¯•ç”¨ä¾‹çš„å®Œæ•´æ€§å’Œå¯æ‰§è¡Œæ€§

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›å¢å¼ºç»“æœï¼š
{
    "preconditions": "å‰ç½®æ¡ä»¶æè¿°",
    "test_steps": [
        {
            "step_number": 1,
            "action": "æ“ä½œæè¿°",
            "data": "æµ‹è¯•æ•°æ®",
            "expected": "æ­¥éª¤é¢„æœŸç»“æœ"
        }
    ],
    "expected_results": "æ•´ä½“é¢„æœŸç»“æœæè¿°"
}

è¦æ±‚ï¼š
- æµ‹è¯•æ­¥éª¤è¦å…·ä½“ã€å¯æ‰§è¡Œ
- å‰ç½®æ¡ä»¶è¦æ˜ç¡®ã€å®Œæ•´
- é¢„æœŸç»“æœè¦æ¸…æ™°ã€å¯éªŒè¯
- ç¡®ä¿é€»è¾‘è¿è´¯æ€§
"""

    def _build_enhancement_prompt(
        self, 
        test_case_data: TestCaseData, 
        message: TestCaseGenerationRequest
    ) -> str:
        """æ„å»ºå¢å¼ºæç¤º"""
        return f"""
è¯·ä¸ºä»¥ä¸‹æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆè¯¦ç»†çš„å‰ç½®æ¡ä»¶ã€æµ‹è¯•æ­¥éª¤å’Œé¢„æœŸç»“æœï¼š

æµ‹è¯•ç”¨ä¾‹æ ‡é¢˜: {test_case_data.title}
æµ‹è¯•ç”¨ä¾‹æè¿°: {test_case_data.description}
æµ‹è¯•ç±»å‹: {test_case_data.test_type}
æµ‹è¯•çº§åˆ«: {test_case_data.test_level}
ä¼˜å…ˆçº§: {test_case_data.priority}

æ¥æºä¿¡æ¯:
- æ¥æºç±»å‹: {message.source_type}
- ç”Ÿæˆé…ç½®: {json.dumps(message.generation_config, ensure_ascii=False, indent=2)}

è¯·ç”Ÿæˆè¯¦ç»†çš„å‰ç½®æ¡ä»¶ã€æµ‹è¯•æ­¥éª¤å’Œé¢„æœŸç»“æœã€‚
"""

    async def _run_ai_enhancement(self, agent, prompt: str) -> str:
        """æ‰§è¡ŒAIå¢å¼º"""
        try:
            stream = agent.run_stream(task=prompt)
            async for event in stream:
                # æµå¼æ¶ˆæ¯
                if isinstance(event, ModelClientStreamingChunkEvent):
                    # ä¸´æ—¶æ³¨é‡Šï¼Œä¸åœ¨å‰ç«¯æ˜¾ç¤ºæµå¼å†…å®¹
                    # await self.send_response(content=event.content, source=self.id.key)
                    continue

                # æœ€ç»ˆçš„å®Œæ•´ç»“æœ
                if isinstance(event, TaskResult):
                    messages = event.messages
                    if messages and hasattr(messages[-1], 'content'):
                        return messages[-1].content

            # è¿”å›é»˜è®¤ç»“æœ
            return self._get_default_enhancement_result()

        except Exception as e:
            logger.error(f"AIå¢å¼ºæ‰§è¡Œå¤±è´¥: {str(e)}")
            return self._get_default_enhancement_result()

    def _get_default_enhancement_result(self) -> str:
        """è·å–é»˜è®¤å¢å¼ºç»“æœ"""
        return """
{
    "preconditions": "ç³»ç»Ÿå·²å¯åŠ¨ï¼Œç”¨æˆ·å·²ç™»å½•",
    "test_steps": [
        {
            "step_number": 1,
            "action": "æ‰§è¡Œæµ‹è¯•æ“ä½œ",
            "data": "æµ‹è¯•æ•°æ®",
            "expected": "æ“ä½œæˆåŠŸ"
        }
    ],
    "expected_results": "æµ‹è¯•é€šè¿‡ï¼ŒåŠŸèƒ½æ­£å¸¸"
}
"""

    async def _send_save_request(
        self,
        message: TestCaseGenerationRequest,
        generation_result: TestCaseGenerationResult
    ) -> TestCaseSaveResponse:
        """å‘é€ä¿å­˜è¯·æ±‚åˆ°æ•°æ®åº“æ™ºèƒ½ä½“"""
        try:
            # æ„å»ºä¿å­˜è¯·æ±‚
            save_request = TestCaseSaveRequest(
                session_id=message.session_id,
                test_cases=generation_result.generated_test_cases,
                project_id=message.generation_config.get("project_id"),
                created_by=message.generation_config.get("created_by"),
                source_metadata={
                    "source_type": message.source_type,
                    "generation_config": message.generation_config,
                    "source_data": message.source_data
                }
            )
            logger.info(f"å·²å‘é€ä¿å­˜è¯·æ±‚åˆ°æ•°æ®åº“æ™ºèƒ½ä½“: {message.session_id}")

            # å‘é€æ¶ˆæ¯åˆ°æ•°æ®åº“ä¿å­˜æ™ºèƒ½ä½“
            test_case_save_response = await self.send_message(
                save_request,
                AgentId(type=TopicTypes.TEST_CASE_SAVER.value, key=self.id.key)
            )
            return test_case_save_response
        except Exception as e:
            logger.error(f"å‘é€ä¿å­˜è¯·æ±‚å¤±è´¥: {str(e)}")
            return TestCaseSaveResponse(
                session_id=message.session_id,
                success=False,
                errors=[str(e)]
            )

    async def _send_mind_map_request(
        self,
        message: TestCaseGenerationRequest,
        saved_test_cases: List[Dict[str, Any]]
    ):
        """å‘é€æ€ç»´å¯¼å›¾ç”Ÿæˆè¯·æ±‚"""
        try:
            await self.send_response("ğŸ§  æ­£åœ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æ€ç»´å¯¼å›¾...")

            # æ„å»ºæ€ç»´å¯¼å›¾ç”Ÿæˆè¯·æ±‚
            mind_map_request = MindMapGenerationRequest(
                session_id=message.session_id,
                test_case_ids=[tc["id"] for tc in saved_test_cases],
                source_data=message.source_data,
                generation_config=message.generation_config
            )

            # å‘é€åˆ°æ€ç»´å¯¼å›¾ç”Ÿæˆæ™ºèƒ½ä½“
            await self.publish_message(
                mind_map_request,
                topic_id=TopicId(type=TopicTypes.MIND_MAP_GENERATOR.value, source=self.id.key)
            )

            logger.info(f"å·²å‘é€æ€ç»´å¯¼å›¾ç”Ÿæˆè¯·æ±‚: {message.session_id}")

        except Exception as e:
            logger.error(f"å‘é€æ€ç»´å¯¼å›¾ç”Ÿæˆè¯·æ±‚å¤±è´¥: {str(e)}")

    async def _handle_empty_generation(
        self,
        message: TestCaseGenerationRequest,
        generation_result: TestCaseGenerationResult
    ):
        """å¤„ç†ç©ºç”Ÿæˆç»“æœ"""
        response = TestCaseGenerationResponse(
            session_id=message.session_id,
            generation_id=str(uuid.uuid4()),
            source_type=message.source_type,
            generated_count=0,
            test_case_ids=[],
            mind_map_generated=False,
            processing_time=generation_result.processing_time,
            created_at=datetime.now().isoformat()
        )

        await self.send_response(
            "âš ï¸ æœªç”Ÿæˆä»»ä½•æµ‹è¯•ç”¨ä¾‹",
            is_final=True,
            result=response.model_dump()
        )

    async def _send_final_response(
        self,
        message: TestCaseGenerationRequest,
        generation_result: TestCaseGenerationResult,
        save_result: TestCaseSaveResponse,
        mind_map_generated: bool,
        start_time: datetime
    ):
        """å‘é€æœ€ç»ˆå“åº”"""
        processing_time = (datetime.now() - start_time).total_seconds()

        response = TestCaseGenerationResponse(
            session_id=message.session_id,
            generation_id=str(uuid.uuid4()),
            source_type=message.source_type,
            generated_count=generation_result.generated_count,
            test_case_ids=[tc["id"] for tc in save_result.saved_test_cases] if save_result.success else [],
            mind_map_generated=mind_map_generated,
            processing_time=processing_time,
            created_at=datetime.now().isoformat()
        )

        if save_result.success:
            await self.send_response(
                f"âœ… æµ‹è¯•ç”¨ä¾‹å¤„ç†å®Œæˆï¼ç”Ÿæˆ {generation_result.generated_count} ä¸ªï¼ŒæˆåŠŸä¿å­˜ {save_result.saved_count} ä¸ª",
                is_final=False,
                result=response.model_dump()
            )
        else:
            await self.send_response(
                f"âš ï¸ æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆï¼Œä½†ä¿å­˜æ—¶å‡ºç°é—®é¢˜ï¼šæˆåŠŸ {save_result.saved_count} ä¸ªï¼Œå¤±è´¥ {save_result.failed_count} ä¸ª",
                is_final=True,
                result=response.model_dump()
            )

    async def _handle_generation_error(
        self,
        message: TestCaseGenerationRequest,
        error: Exception,
        start_time: datetime
    ):
        """å¤„ç†ç”Ÿæˆé”™è¯¯"""
        processing_time = (datetime.now() - start_time).total_seconds()

        error_response = TestCaseGenerationResponse(
            session_id=message.session_id,
            generation_id=str(uuid.uuid4()),
            source_type=message.source_type,
            generated_count=0,
            test_case_ids=[],
            mind_map_generated=False,
            processing_time=processing_time,
            created_at=datetime.now().isoformat()
        )

        await self.send_response(
            f"âŒ æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥: {str(error)}",
            is_final=True,
            result=error_response.model_dump()
        )

        logger.error(f"æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥: {message.session_id}, é”™è¯¯: {str(error)}")

    def _update_average_processing_time(self, start_time: datetime):
        """æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´"""
        processing_time = (datetime.now() - start_time).total_seconds()
        current_avg = self.generation_metrics["average_processing_time"]
        total_requests = self.generation_metrics["total_requests"]

        # è®¡ç®—æ–°çš„å¹³å‡å€¼
        new_avg = ((current_avg * (total_requests - 1)) + processing_time) / total_requests
        self.generation_metrics["average_processing_time"] = new_avg

    def get_performance_metrics(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        return {
            **self.generation_metrics,
            "success_rate": (
                self.generation_metrics["successful_generations"] /
                max(self.generation_metrics["total_requests"], 1)
            ) * 100,
            "agent_name": self.agent_name,
            "agent_id": self.id.key
        }
