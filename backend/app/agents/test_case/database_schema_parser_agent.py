"""
æ•°æ®åº“Schemaè§£ææ™ºèƒ½ä½“
è´Ÿè´£è§£ææ•°æ®åº“è¡¨ç»“æ„ï¼Œç”Ÿæˆæ•°æ®æµ‹è¯•ç”¨ä¾‹
"""
import uuid
import json
import re
from typing import Dict, List, Any, Optional
from datetime import datetime

from autogen_core import message_handler, type_subscription, MessageContext, TopicId
from loguru import logger
from pydantic import BaseModel, Field

from app.core.agents.base import BaseAgent
from app.core.types import TopicTypes, AgentTypes, AGENT_NAMES
from app.core.messages.test_case import (
    DatabaseSchemaParseRequest, DatabaseSchemaParseResponse,
    TestCaseData
)
from app.core.enums import TestType, TestLevel, Priority, InputSource


class DatabaseColumn(BaseModel):
    """æ•°æ®åº“åˆ—ä¿¡æ¯"""
    name: str = Field(..., description="åˆ—å")
    data_type: str = Field(..., description="æ•°æ®ç±»å‹")
    is_nullable: bool = Field(True, description="æ˜¯å¦å¯ä¸ºç©º")
    is_primary_key: bool = Field(False, description="æ˜¯å¦ä¸»é”®")
    is_foreign_key: bool = Field(False, description="æ˜¯å¦å¤–é”®")
    default_value: Optional[str] = Field(None, description="é»˜è®¤å€¼")
    max_length: Optional[int] = Field(None, description="æœ€å¤§é•¿åº¦")
    constraints: List[str] = Field(default_factory=list, description="çº¦æŸæ¡ä»¶")
    comment: str = Field("", description="åˆ—æ³¨é‡Š")


class DatabaseTable(BaseModel):
    """æ•°æ®åº“è¡¨ä¿¡æ¯"""
    name: str = Field(..., description="è¡¨å")
    schema: str = Field("", description="æ¨¡å¼å")
    columns: List[DatabaseColumn] = Field(default_factory=list, description="åˆ—ä¿¡æ¯")
    primary_keys: List[str] = Field(default_factory=list, description="ä¸»é”®åˆ—")
    foreign_keys: List[Dict[str, str]] = Field(default_factory=list, description="å¤–é”®å…³ç³»")
    indexes: List[Dict[str, Any]] = Field(default_factory=list, description="ç´¢å¼•ä¿¡æ¯")
    comment: str = Field("", description="è¡¨æ³¨é‡Š")


class DatabaseSchemaParseResult(BaseModel):
    """æ•°æ®åº“Schemaè§£æç»“æœ"""
    database_type: str = Field("", description="æ•°æ®åº“ç±»å‹")
    database_name: str = Field("", description="æ•°æ®åº“åç§°")
    tables: List[DatabaseTable] = Field(default_factory=list, description="è¡¨åˆ—è¡¨")
    relationships: List[Dict[str, Any]] = Field(default_factory=list, description="è¡¨å…³ç³»")
    constraints: List[Dict[str, Any]] = Field(default_factory=list, description="çº¦æŸä¿¡æ¯")
    confidence_score: float = Field(0.0, description="è§£æç½®ä¿¡åº¦")


@type_subscription(topic_type=TopicTypes.DATABASE_SCHEMA_PARSER.value)
class DatabaseSchemaParserAgent(BaseAgent):
    """æ•°æ®åº“Schemaè§£ææ™ºèƒ½ä½“ï¼Œè´Ÿè´£è§£ææ•°æ®åº“è¡¨ç»“æ„"""

    def __init__(self, model_client_instance=None, **kwargs):
        """åˆå§‹åŒ–æ•°æ®åº“Schemaè§£ææ™ºèƒ½ä½“"""
        super().__init__(
            agent_id=AgentTypes.DATABASE_SCHEMA_PARSER.value,
            agent_name=AGENT_NAMES.get(AgentTypes.DATABASE_SCHEMA_PARSER.value, "æ•°æ®åº“Schemaè§£ææ™ºèƒ½ä½“"),
            model_client_instance=model_client_instance,
            **kwargs
        )
        
        # æ”¯æŒçš„æ•°æ®åº“ç±»å‹
        self.supported_databases = {
            'mysql': self._parse_mysql_schema,
            'postgresql': self._parse_postgresql_schema,
            'oracle': self._parse_oracle_schema,
            'sqlserver': self._parse_sqlserver_schema,
            'sqlite': self._parse_sqlite_schema
        }
        
        logger.info(f"æ•°æ®åº“Schemaè§£ææ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ: {self.agent_name}")

    @message_handler
    async def handle_database_schema_parse_request(
        self, 
        message: DatabaseSchemaParseRequest, 
        ctx: MessageContext
    ) -> None:
        """å¤„ç†æ•°æ®åº“Schemaè§£æè¯·æ±‚"""
        try:
            logger.info(f"å¼€å§‹å¤„ç†æ•°æ®åº“Schemaè§£æè¯·æ±‚: {message.session_id}")
            
            await self.send_response(
                f"ğŸ” å¼€å§‹è§£ææ•°æ®åº“Schema: {message.database_name}",
                region="process"
            )
            
            # è§£ææ•°æ®åº“Schema
            parse_result = await self._parse_database_schema(message)
            
            # ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
            test_cases = await self._generate_test_cases_from_schema(
                parse_result, message
            )
            
            # æ„å»ºå“åº”
            response = DatabaseSchemaParseResponse(
                session_id=message.session_id,
                schema_id=str(uuid.uuid4()),
                database_name=message.database_name,
                database_type=message.database_type,
                parse_result=parse_result.model_dump(),
                test_cases=test_cases,
                processing_time=0.0,
                created_at=datetime.now().isoformat()
            )
            
            await self.send_response(
                f"âœ… æ•°æ®åº“Schemaè§£æå®Œæˆï¼Œå‘ç° {len(parse_result.tables)} ä¸ªè¡¨",
                is_final=True,
                result=response.model_dump()
            )
            
            # å‘é€åˆ°æµ‹è¯•ç‚¹æå–æ™ºèƒ½ä½“
            await self._send_to_test_point_extractor(response)
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“Schemaè§£æå¤±è´¥: {str(e)}")
            await self.send_response(
                f"âŒ æ•°æ®åº“Schemaè§£æå¤±è´¥: {str(e)}",
                is_final=True,
                error=str(e)
            )

    async def _parse_database_schema(
        self, 
        message: DatabaseSchemaParseRequest
    ) -> DatabaseSchemaParseResult:
        """è§£ææ•°æ®åº“Schema"""
        try:
            database_type = message.database_type.lower()
            
            if database_type not in self.supported_databases:
                raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®åº“ç±»å‹: {database_type}")
            
            await self.send_response(f"ğŸ“Š æ­£åœ¨è§£æ {database_type} æ•°æ®åº“Schema...")
            
            # æ ¹æ®è¾“å…¥ç±»å‹é€‰æ‹©è§£ææ–¹æ³•
            if message.schema_file_path:
                # ä»æ–‡ä»¶è§£æ
                parse_result = await self._parse_schema_from_file(message)
            elif message.connection_string:
                # ä»æ•°æ®åº“è¿æ¥è§£æ
                parse_result = await self._parse_schema_from_connection(message)
            elif message.schema_sql:
                # ä»SQLè¯­å¥è§£æ
                parse_result = await self._parse_schema_from_sql(message)
            else:
                raise ValueError("ç¼ºå°‘Schemaæ•°æ®æº")
            
            return parse_result
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“Schemaè§£æå¤±è´¥: {str(e)}")
            raise

    async def _parse_schema_from_file(
        self, 
        message: DatabaseSchemaParseRequest
    ) -> DatabaseSchemaParseResult:
        """ä»æ–‡ä»¶è§£æSchema"""
        try:
            with open(message.schema_file_path, 'r', encoding='utf-8') as f:
                schema_content = f.read()
            
            return await self._parse_schema_content(schema_content, message)
            
        except Exception as e:
            logger.error(f"ä»æ–‡ä»¶è§£æSchemaå¤±è´¥: {str(e)}")
            raise

    async def _parse_schema_from_connection(
        self, 
        message: DatabaseSchemaParseRequest
    ) -> DatabaseSchemaParseResult:
        """ä»æ•°æ®åº“è¿æ¥è§£æSchema"""
        try:
            # è¿™é‡Œéœ€è¦å®ç°å®é™…çš„æ•°æ®åº“è¿æ¥é€»è¾‘
            # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿç»“æœ
            await self.send_response("âš ï¸ æ•°æ®åº“è¿æ¥è§£æåŠŸèƒ½å¼€å‘ä¸­ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            
            return DatabaseSchemaParseResult(
                database_type=message.database_type,
                database_name=message.database_name,
                tables=[],
                relationships=[],
                constraints=[],
                confidence_score=0.5
            )
            
        except Exception as e:
            logger.error(f"ä»æ•°æ®åº“è¿æ¥è§£æSchemaå¤±è´¥: {str(e)}")
            raise

    async def _parse_schema_from_sql(
        self, 
        message: DatabaseSchemaParseRequest
    ) -> DatabaseSchemaParseResult:
        """ä»SQLè¯­å¥è§£æSchema"""
        try:
            return await self._parse_schema_content(message.schema_sql, message)
            
        except Exception as e:
            logger.error(f"ä»SQLè¯­å¥è§£æSchemaå¤±è´¥: {str(e)}")
            raise

    async def _parse_schema_content(
        self, 
        schema_content: str, 
        message: DatabaseSchemaParseRequest
    ) -> DatabaseSchemaParseResult:
        """è§£æSchemaå†…å®¹"""
        try:
            database_type = message.database_type.lower()
            parser_func = self.supported_databases[database_type]
            
            # è°ƒç”¨å¯¹åº”çš„è§£ææ–¹æ³•
            tables = await parser_func(schema_content)
            
            # åˆ†æè¡¨å…³ç³»
            relationships = await self._analyze_table_relationships(tables)
            
            # æå–çº¦æŸä¿¡æ¯
            constraints = await self._extract_constraints(tables)
            
            return DatabaseSchemaParseResult(
                database_type=database_type,
                database_name=message.database_name,
                tables=tables,
                relationships=relationships,
                constraints=constraints,
                confidence_score=0.9
            )
            
        except Exception as e:
            logger.error(f"è§£æSchemaå†…å®¹å¤±è´¥: {str(e)}")
            raise

    async def _parse_mysql_schema(self, schema_content: str) -> List[DatabaseTable]:
        """è§£æMySQL Schema"""
        try:
            tables = []
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æCREATE TABLEè¯­å¥
            table_pattern = r'CREATE TABLE\s+(?:`?(\w+)`?)\s*\((.*?)\)(?:\s*ENGINE\s*=\s*\w+)?(?:\s*DEFAULT\s+CHARSET\s*=\s*\w+)?(?:\s*COMMENT\s*=\s*[\'"]([^\'"]*)[\'"])?'
            
            for match in re.finditer(table_pattern, schema_content, re.IGNORECASE | re.DOTALL):
                table_name = match.group(1)
                columns_def = match.group(2)
                table_comment = match.group(3) or ""
                
                # è§£æåˆ—å®šä¹‰
                columns = await self._parse_mysql_columns(columns_def)
                
                # æå–ä¸»é”®å’Œå¤–é”®
                primary_keys = [col.name for col in columns if col.is_primary_key]
                foreign_keys = [
                    {"column": col.name, "references": "unknown"}
                    for col in columns if col.is_foreign_key
                ]
                
                table = DatabaseTable(
                    name=table_name,
                    columns=columns,
                    primary_keys=primary_keys,
                    foreign_keys=foreign_keys,
                    comment=table_comment
                )
                tables.append(table)
            
            return tables
            
        except Exception as e:
            logger.error(f"è§£æMySQL Schemaå¤±è´¥: {str(e)}")
            return []

    async def _parse_mysql_columns(self, columns_def: str) -> List[DatabaseColumn]:
        """è§£æMySQLåˆ—å®šä¹‰"""
        try:
            columns = []
            
            # åˆ†å‰²åˆ—å®šä¹‰
            column_lines = [line.strip() for line in columns_def.split(',')]
            
            for line in column_lines:
                if not line or line.upper().startswith(('PRIMARY KEY', 'FOREIGN KEY', 'KEY', 'INDEX')):
                    continue
                
                # è§£æåˆ—å®šä¹‰
                column = await self._parse_mysql_column_line(line)
                if column:
                    columns.append(column)
            
            return columns
            
        except Exception as e:
            logger.error(f"è§£æMySQLåˆ—å®šä¹‰å¤±è´¥: {str(e)}")
            return []

    async def _parse_mysql_column_line(self, line: str) -> Optional[DatabaseColumn]:
        """è§£æMySQLå•ä¸ªåˆ—å®šä¹‰"""
        try:
            # ç®€åŒ–çš„åˆ—è§£æé€»è¾‘
            parts = line.split()
            if len(parts) < 2:
                return None
            
            column_name = parts[0].strip('`')
            data_type = parts[1]
            
            # æ£€æŸ¥çº¦æŸ
            is_nullable = 'NOT NULL' not in line.upper()
            is_primary_key = 'PRIMARY KEY' in line.upper()
            is_auto_increment = 'AUTO_INCREMENT' in line.upper()
            
            # æå–æ³¨é‡Š
            comment_match = re.search(r"COMMENT\s+['\"]([^'\"]*)['\"]", line, re.IGNORECASE)
            comment = comment_match.group(1) if comment_match else ""
            
            return DatabaseColumn(
                name=column_name,
                data_type=data_type,
                is_nullable=is_nullable,
                is_primary_key=is_primary_key,
                constraints=['AUTO_INCREMENT'] if is_auto_increment else [],
                comment=comment
            )
            
        except Exception as e:
            logger.warning(f"è§£æåˆ—å®šä¹‰å¤±è´¥: {line}, é”™è¯¯: {str(e)}")
            return None

    async def _parse_postgresql_schema(self, schema_content: str) -> List[DatabaseTable]:
        """è§£æPostgreSQL Schema"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥æ›´å¤æ‚
        return await self._parse_mysql_schema(schema_content)

    async def _parse_oracle_schema(self, schema_content: str) -> List[DatabaseTable]:
        """è§£æOracle Schema"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥æ›´å¤æ‚
        return await self._parse_mysql_schema(schema_content)

    async def _parse_sqlserver_schema(self, schema_content: str) -> List[DatabaseTable]:
        """è§£æSQL Server Schema"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥æ›´å¤æ‚
        return await self._parse_mysql_schema(schema_content)

    async def _parse_sqlite_schema(self, schema_content: str) -> List[DatabaseTable]:
        """è§£æSQLite Schema"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥æ›´å¤æ‚
        return await self._parse_mysql_schema(schema_content)

    async def _analyze_table_relationships(
        self, 
        tables: List[DatabaseTable]
    ) -> List[Dict[str, Any]]:
        """åˆ†æè¡¨å…³ç³»"""
        try:
            relationships = []
            
            for table in tables:
                for fk in table.foreign_keys:
                    relationship = {
                        "from_table": table.name,
                        "from_column": fk["column"],
                        "to_table": fk.get("references", "unknown"),
                        "relationship_type": "one_to_many"
                    }
                    relationships.append(relationship)
            
            return relationships
            
        except Exception as e:
            logger.error(f"åˆ†æè¡¨å…³ç³»å¤±è´¥: {str(e)}")
            return []

    async def _extract_constraints(
        self, 
        tables: List[DatabaseTable]
    ) -> List[Dict[str, Any]]:
        """æå–çº¦æŸä¿¡æ¯"""
        try:
            constraints = []
            
            for table in tables:
                for column in table.columns:
                    if column.constraints:
                        constraint = {
                            "table": table.name,
                            "column": column.name,
                            "constraints": column.constraints
                        }
                        constraints.append(constraint)
            
            return constraints
            
        except Exception as e:
            logger.error(f"æå–çº¦æŸä¿¡æ¯å¤±è´¥: {str(e)}")
            return []

    async def _generate_test_cases_from_schema(
        self, 
        parse_result: DatabaseSchemaParseResult,
        message: DatabaseSchemaParseRequest
    ) -> List[TestCaseData]:
        """ä»æ•°æ®åº“Schemaç”Ÿæˆæµ‹è¯•ç”¨ä¾‹"""
        test_cases = []
        
        try:
            # ä¸ºæ¯ä¸ªè¡¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
            for table in parse_result.tables:
                # æ•°æ®æ’å…¥æµ‹è¯•
                insert_test_case = TestCaseData(
                    title=f"æµ‹è¯• {table.name} è¡¨æ•°æ®æ’å…¥",
                    description=f"æµ‹è¯•å‘ {table.name} è¡¨æ’å…¥æ•°æ®çš„åŠŸèƒ½",
                    test_type=TestType.DATABASE,
                    test_level=TestLevel.INTEGRATION,
                    priority=Priority.P1,
                    input_source=InputSource.DATABASE_SCHEMA,
                    ai_confidence=parse_result.confidence_score
                )
                test_cases.append(insert_test_case)
                
                # æ•°æ®æŸ¥è¯¢æµ‹è¯•
                select_test_case = TestCaseData(
                    title=f"æµ‹è¯• {table.name} è¡¨æ•°æ®æŸ¥è¯¢",
                    description=f"æµ‹è¯•ä» {table.name} è¡¨æŸ¥è¯¢æ•°æ®çš„åŠŸèƒ½",
                    test_type=TestType.DATABASE,
                    test_level=TestLevel.INTEGRATION,
                    priority=Priority.P2,
                    input_source=InputSource.DATABASE_SCHEMA,
                    ai_confidence=parse_result.confidence_score
                )
                test_cases.append(select_test_case)
                
                # æ•°æ®æ›´æ–°æµ‹è¯•
                update_test_case = TestCaseData(
                    title=f"æµ‹è¯• {table.name} è¡¨æ•°æ®æ›´æ–°",
                    description=f"æµ‹è¯•æ›´æ–° {table.name} è¡¨æ•°æ®çš„åŠŸèƒ½",
                    test_type=TestType.DATABASE,
                    test_level=TestLevel.INTEGRATION,
                    priority=Priority.P2,
                    input_source=InputSource.DATABASE_SCHEMA,
                    ai_confidence=parse_result.confidence_score
                )
                test_cases.append(update_test_case)
                
                # æ•°æ®åˆ é™¤æµ‹è¯•
                delete_test_case = TestCaseData(
                    title=f"æµ‹è¯• {table.name} è¡¨æ•°æ®åˆ é™¤",
                    description=f"æµ‹è¯•åˆ é™¤ {table.name} è¡¨æ•°æ®çš„åŠŸèƒ½",
                    test_type=TestType.DATABASE,
                    test_level=TestLevel.INTEGRATION,
                    priority=Priority.P2,
                    input_source=InputSource.DATABASE_SCHEMA,
                    source_metadata={
                        "database_name": message.database_name,
                        "table_name": table.name,
                        "test_focus": "delete"
                    },
                    ai_confidence=parse_result.confidence_score
                )
                test_cases.append(delete_test_case)
                
                # çº¦æŸéªŒè¯æµ‹è¯•
                if any(col.constraints for col in table.columns):
                    constraint_test_case = TestCaseData(
                        title=f"æµ‹è¯• {table.name} è¡¨çº¦æŸéªŒè¯",
                        description=f"æµ‹è¯• {table.name} è¡¨çš„æ•°æ®çº¦æŸéªŒè¯",
                        test_type=TestType.DATABASE,
                        test_level=TestLevel.INTEGRATION,
                        priority=Priority.P1,
                        input_source=InputSource.DATABASE_SCHEMA,
                        source_metadata={
                            "database_name": message.database_name,
                            "table_name": table.name,
                            "test_focus": "constraints"
                        },
                        ai_confidence=parse_result.confidence_score
                    )
                    test_cases.append(constraint_test_case)
            
            # å…³ç³»å®Œæ•´æ€§æµ‹è¯•
            if parse_result.relationships:
                relationship_test_case = TestCaseData(
                    title=f"æµ‹è¯• {parse_result.database_name} æ•°æ®åº“å…³ç³»å®Œæ•´æ€§",
                    description="æµ‹è¯•æ•°æ®åº“è¡¨ä¹‹é—´çš„å…³ç³»å®Œæ•´æ€§",
                    test_type=TestType.DATABASE,
                    test_level=TestLevel.SYSTEM,
                    priority=Priority.P1,
                    input_source=InputSource.DATABASE_SCHEMA,
                    ai_confidence=parse_result.confidence_score
                )
                test_cases.append(relationship_test_case)
            
            logger.info(f"ä»æ•°æ®åº“Schemaç”Ÿæˆäº† {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
            return test_cases
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å¤±è´¥: {str(e)}")
            return []

    async def _send_to_test_point_extractor(self, response: DatabaseSchemaParseResponse):
        """å‘é€åˆ°æµ‹è¯•ç‚¹æå–æ™ºèƒ½ä½“"""
        try:
            from app.core.messages.test_case import TestPointExtractionRequest

            # æ„å»ºéœ€æ±‚è§£æç»“æœ
            requirement_analysis_result = {
                "source_type": "database_schema",
                "database_name": response.database_name,
                "database_type": response.database_type,
                "schema_analysis": response.parse_result,
                "requirements": [tc.model_dump() for tc in response.test_cases],
                "tables": response.parse_result.get("tables", []),
                "relationships": response.parse_result.get("relationships", []),
                "constraints": response.parse_result.get("constraints", []),
                "indexes": response.parse_result.get("indexes", []),
                "data_types": response.parse_result.get("data_types", [])
            }

            extraction_request = TestPointExtractionRequest(
                session_id=response.session_id,
                requirement_analysis_result=requirement_analysis_result,
                extraction_config={
                    "enable_functional_testing": True,
                    "enable_non_functional_testing": True,
                    "enable_integration_testing": True,
                    "enable_acceptance_testing": True,
                    "enable_boundary_testing": True,
                    "enable_exception_testing": True,
                    "test_depth": "comprehensive",
                    "focus_areas": ["data_integrity", "performance", "security", "backup_recovery"]
                },
                test_strategy="database_driven"
            )

            await self.publish_message(
                extraction_request,
                topic_id=TopicId(type=TopicTypes.TEST_POINT_EXTRACTOR.value, source=self.id.key)
            )

            logger.info(f"å·²å‘é€åˆ°æµ‹è¯•ç‚¹æå–æ™ºèƒ½ä½“: {response.session_id}")

        except Exception as e:
            logger.error(f"å‘é€åˆ°æµ‹è¯•ç‚¹æå–æ™ºèƒ½ä½“å¤±è´¥: {str(e)}")
